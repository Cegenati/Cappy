{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2906d21-ee68-4a7c-ada3-04e323b205b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading data\n",
    "import os\n",
    "os.environ[\"PTB_FOLDER_PATH\"] = \"/home/jupyter/data/files/ptbdb/1.0.0/\"\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/jupyter/Cappy/ptd_data_handler\")\n",
    "sys.path.insert(0,\"/home/jupyter/Cappy/signal_processing\")\n",
    "from ptb_data_formatter import *\n",
    "from feature_extraction import *\n",
    "from custom_processing import *\n",
    "#all_patient_data = get_formatted_ptb_data()\n",
    "from ptb_xl_data_formatter import *\n",
    "os.environ[\"PTB_XL_FOLDER_PATH\"] = \"/home/jupyter/data/physionet.org/files/ptb-xl/1.0.1\"\n",
    "all_patient_data = get_formatted_ptb_xl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b223233-9187-45c8-9eba-380a2af6448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae82c67-5781-4bca-940d-3e70b636b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90043475-653d-4b3c-abdf-cbbfb98b8711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create individual df for each class\n",
    "mi_df = pd.DataFrame()\n",
    "norm_df = pd.DataFrame()\n",
    "non_mi_df = pd.DataFrame()\n",
    "\n",
    "for recording in all_patient_data.keys():\n",
    "    label = all_patient_data[recording][\"diagnostic_class\"][0]\n",
    "    signal = all_patient_data[recording][\"I\"]\n",
    "    \n",
    "    # Clean Signal\n",
    "    signal = clean_ecg_signal(signal, old_fs=500)\n",
    "    signal = pd.DataFrame(signal)\n",
    "    if label == \"mi\":\n",
    "        mi_df[recording] = signal\n",
    "    elif label == \"norm\":\n",
    "        norm_df[recording] = signal\n",
    "    elif label == \"non_mi\":\n",
    "        non_mi_df[recording] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44118d-d371-4fd8-8530-db70995e34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_1</th>\n",
       "      <th>ecg_id_2</th>\n",
       "      <th>ecg_id_3</th>\n",
       "      <th>ecg_id_4</th>\n",
       "      <th>ecg_id_5</th>\n",
       "      <th>ecg_id_6</th>\n",
       "      <th>ecg_id_7</th>\n",
       "      <th>ecg_id_9</th>\n",
       "      <th>ecg_id_10</th>\n",
       "      <th>ecg_id_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21814</th>\n",
       "      <th>ecg_id_21818</th>\n",
       "      <th>ecg_id_21822</th>\n",
       "      <th>ecg_id_21823</th>\n",
       "      <th>ecg_id_21825</th>\n",
       "      <th>ecg_id_21830</th>\n",
       "      <th>ecg_id_21831</th>\n",
       "      <th>ecg_id_21834</th>\n",
       "      <th>ecg_id_21836</th>\n",
       "      <th>ecg_id_21837</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>-0.039000</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.028732</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>-0.021314</td>\n",
       "      <td>-0.039865</td>\n",
       "      <td>0.029101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023012</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.016769</td>\n",
       "      <td>-0.006891</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.007398</td>\n",
       "      <td>-0.006681</td>\n",
       "      <td>-0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012923</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>-0.040540</td>\n",
       "      <td>-0.003672</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.029169</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-0.040053</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023845</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>-0.008623</td>\n",
       "      <td>-0.004408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015592</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-0.004065</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.029958</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.030743</td>\n",
       "      <td>-0.040922</td>\n",
       "      <td>0.034173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.004136</td>\n",
       "      <td>-0.023896</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>-0.015739</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>-0.010028</td>\n",
       "      <td>-0.004711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017107</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>-0.043554</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.030994</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.032745</td>\n",
       "      <td>-0.042824</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024848</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>-0.024516</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>-0.003093</td>\n",
       "      <td>-0.010945</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>-0.044784</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.004724</td>\n",
       "      <td>-0.032476</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024894</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>-0.004322</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.010007</td>\n",
       "      <td>-0.004983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.005493</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>-0.007596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.004969</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.005355</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>-0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>-0.003660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.004574</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>-0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.004258</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>-0.005464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.003666</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>-0.004658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 8938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_1  ecg_id_2  ecg_id_3  ecg_id_4  ecg_id_5  ecg_id_6  ecg_id_7  \\\n",
       "0    -0.009347  0.003970 -0.039000 -0.003108 -0.000459 -0.028732 -0.004423   \n",
       "1    -0.012923  0.004130 -0.040540 -0.003672 -0.000078 -0.029169 -0.004455   \n",
       "2    -0.015592  0.004313 -0.042083 -0.004065  0.000122 -0.029958 -0.004510   \n",
       "3    -0.017107  0.004451 -0.043554 -0.004296  0.000013 -0.030994 -0.004599   \n",
       "4    -0.017702  0.004352 -0.044784 -0.004461 -0.000443 -0.031639 -0.004724   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4595  0.005499 -0.000025 -0.005809 -0.003973 -0.000129  0.003427 -0.000903   \n",
       "4596  0.004969 -0.000020 -0.005355 -0.003513 -0.000112  0.003118 -0.000827   \n",
       "4597  0.004487  0.000015 -0.004830 -0.002628 -0.000100  0.002773 -0.000746   \n",
       "4598  0.004102  0.000069 -0.004258 -0.001457 -0.000090  0.002404 -0.000664   \n",
       "4599  0.003807  0.000131 -0.003666 -0.000155 -0.000081  0.002027 -0.000581   \n",
       "\n",
       "      ecg_id_9  ecg_id_10  ecg_id_11  ...  ecg_id_21814  ecg_id_21818  \\\n",
       "0    -0.021314  -0.039865   0.029101  ...     -0.023012     -0.001422   \n",
       "1    -0.026685  -0.040053   0.031884  ...     -0.023845     -0.001576   \n",
       "2    -0.030743  -0.040922   0.034173  ...     -0.024496     -0.001693   \n",
       "3    -0.032745  -0.042824   0.035931  ...     -0.024848     -0.001744   \n",
       "4    -0.032476  -0.045653   0.037407  ...     -0.024894     -0.001723   \n",
       "...        ...        ...        ...  ...           ...           ...   \n",
       "4595  0.001467  -0.001330  -0.004544  ...     -0.000153     -0.003259   \n",
       "4596  0.001179  -0.001239  -0.004117  ...     -0.000156     -0.002987   \n",
       "4597  0.001030  -0.001149  -0.003660  ...     -0.000158     -0.002663   \n",
       "4598  0.001095  -0.001061  -0.003228  ...     -0.000160     -0.002303   \n",
       "4599  0.001340  -0.000972  -0.002839  ...     -0.000163     -0.001929   \n",
       "\n",
       "      ecg_id_21822  ecg_id_21823  ecg_id_21825  ecg_id_21830  ecg_id_21831  \\\n",
       "0        -0.003744     -0.021490     -0.016769     -0.006891     -0.002969   \n",
       "1        -0.003956     -0.022829     -0.012274     -0.011858     -0.003013   \n",
       "2        -0.004136     -0.023896     -0.008044     -0.015739     -0.003054   \n",
       "3        -0.004260     -0.024516     -0.004839     -0.017761     -0.003093   \n",
       "4        -0.004322     -0.024624     -0.004421     -0.017430     -0.003139   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.001467     -0.001109     -0.001520      0.000290     -0.005493   \n",
       "4596      0.001340     -0.001026     -0.001357      0.000260     -0.005039   \n",
       "4597      0.001202     -0.000937     -0.001185      0.000295     -0.004574   \n",
       "4598      0.001057     -0.000844     -0.001008      0.000377     -0.004103   \n",
       "4599      0.000908     -0.000748     -0.000831      0.000483     -0.003630   \n",
       "\n",
       "      ecg_id_21834  ecg_id_21836  ecg_id_21837  \n",
       "0        -0.007398     -0.006681     -0.004043  \n",
       "1        -0.009197     -0.008623     -0.004408  \n",
       "2        -0.010527     -0.010028     -0.004711  \n",
       "3        -0.010945     -0.010549     -0.004907  \n",
       "4        -0.010145     -0.010007     -0.004983  \n",
       "...            ...           ...           ...  \n",
       "4595      0.000944      0.004262     -0.007596  \n",
       "4596      0.000856      0.003903     -0.006966  \n",
       "4597      0.000773      0.003509     -0.006244  \n",
       "4598      0.000695      0.003093     -0.005464  \n",
       "4599      0.000619      0.002671     -0.004658  \n",
       "\n",
       "[4600 rows x 8938 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee3ee7-7c18-4b0a-ba01-2b1a9c92264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_77</th>\n",
       "      <th>ecg_id_106</th>\n",
       "      <th>ecg_id_131</th>\n",
       "      <th>ecg_id_139</th>\n",
       "      <th>ecg_id_152</th>\n",
       "      <th>ecg_id_162</th>\n",
       "      <th>ecg_id_177</th>\n",
       "      <th>ecg_id_181</th>\n",
       "      <th>ecg_id_184</th>\n",
       "      <th>ecg_id_189</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21788</th>\n",
       "      <th>ecg_id_21793</th>\n",
       "      <th>ecg_id_21796</th>\n",
       "      <th>ecg_id_21799</th>\n",
       "      <th>ecg_id_21805</th>\n",
       "      <th>ecg_id_21811</th>\n",
       "      <th>ecg_id_21815</th>\n",
       "      <th>ecg_id_21826</th>\n",
       "      <th>ecg_id_21827</th>\n",
       "      <th>ecg_id_21828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038216</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.018618</td>\n",
       "      <td>-0.024321</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>-0.007663</td>\n",
       "      <td>-0.032769</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.353304</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.019221</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>-0.028041</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>-0.009266</td>\n",
       "      <td>-0.032548</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.021936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.360804</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.020913</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>-0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039715</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.019885</td>\n",
       "      <td>-0.030967</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>-0.032718</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.022117</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>-0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040454</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.020368</td>\n",
       "      <td>-0.032966</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.010664</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>0.396816</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>-0.022629</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>-0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040977</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>-0.034439</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.034861</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>0.438201</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>-0.022710</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>-0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>-0.008708</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018354</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.007124</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.006392</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.006327</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.001831</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>-0.002459</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 4145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_77  ecg_id_106  ecg_id_131  ecg_id_139  ecg_id_152  ecg_id_162  \\\n",
       "0     -0.038216   -0.000989   -0.018618   -0.024321   -0.004008    0.004239   \n",
       "1     -0.038924   -0.000582   -0.019282   -0.028041   -0.004006    0.004611   \n",
       "2     -0.039715   -0.000276   -0.019885   -0.030967   -0.003715    0.004879   \n",
       "3     -0.040454   -0.000139   -0.020368   -0.032966   -0.002968    0.004980   \n",
       "4     -0.040977   -0.000192   -0.020707   -0.034439   -0.001936    0.004937   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "4595  -0.000371   -0.003030   -0.001336   -0.012455    0.003633    0.000759   \n",
       "4596  -0.000364   -0.002777   -0.001236   -0.011647    0.003335    0.000700   \n",
       "4597  -0.000373   -0.002482   -0.001112   -0.010651    0.003025    0.000636   \n",
       "4598  -0.000401   -0.002162   -0.000973   -0.009366    0.002709    0.000570   \n",
       "4599  -0.000443   -0.001831   -0.000828   -0.007837    0.002391    0.000503   \n",
       "\n",
       "      ecg_id_177  ecg_id_181  ecg_id_184  ecg_id_189  ...  ecg_id_21788  \\\n",
       "0      -0.007663   -0.032769    0.008102    0.020674  ...     -0.003852   \n",
       "1      -0.009266   -0.032548    0.006741    0.021936  ...     -0.003325   \n",
       "2      -0.010420   -0.032718    0.005921    0.022862  ...     -0.003049   \n",
       "3      -0.010664   -0.033484    0.005843    0.023257  ...     -0.003045   \n",
       "4      -0.009600   -0.034861    0.006418    0.023114  ...     -0.003172   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "4595   -0.008535   -0.007130   -0.004652    0.002573  ...     -0.020067   \n",
       "4596   -0.007842   -0.006564   -0.004190    0.002382  ...     -0.018354   \n",
       "4597   -0.007124   -0.005976   -0.003465    0.002184  ...     -0.016345   \n",
       "4598   -0.006392   -0.005377   -0.002566    0.001982  ...     -0.014145   \n",
       "4599   -0.005655   -0.004774   -0.001587    0.001780  ...     -0.011864   \n",
       "\n",
       "      ecg_id_21793  ecg_id_21796  ecg_id_21799  ecg_id_21805  ecg_id_21811  \\\n",
       "0         0.353304      0.013632      0.012455      0.000497     -0.019221   \n",
       "1         0.360804      0.014458      0.013331      0.000873     -0.020913   \n",
       "2         0.373210      0.015139      0.014043      0.001158     -0.022117   \n",
       "3         0.396816      0.015568      0.014469      0.001291     -0.022629   \n",
       "4         0.438201      0.015712      0.014571      0.001255     -0.022710   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.009014     -0.000256      0.002257     -0.003724     -0.008708   \n",
       "4596      0.009014     -0.000223      0.002080     -0.003414     -0.007997   \n",
       "4597      0.008317     -0.000192      0.001892     -0.003097     -0.007192   \n",
       "4598      0.006642     -0.000162      0.001700     -0.002778     -0.006327   \n",
       "4599      0.004176     -0.000134      0.001505     -0.002459     -0.005438   \n",
       "\n",
       "      ecg_id_21815  ecg_id_21826  ecg_id_21827  ecg_id_21828  \n",
       "0         0.005553      0.011715      0.010180     -0.001342  \n",
       "1         0.006690      0.011091      0.010963     -0.001450  \n",
       "2         0.008079      0.010091      0.011743     -0.001540  \n",
       "3         0.009693      0.008625      0.012379     -0.001597  \n",
       "4         0.011035      0.007408      0.012609     -0.001618  \n",
       "...            ...           ...           ...           ...  \n",
       "4595      0.002847      0.001047      0.000090      0.001465  \n",
       "4596      0.002616      0.000958      0.000097      0.001339  \n",
       "4597      0.002389      0.000856      0.000102      0.001210  \n",
       "4598      0.002166      0.000748      0.000105      0.001079  \n",
       "4599      0.001945      0.000636      0.000109      0.000947  \n",
       "\n",
       "[4600 rows x 4145 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8b9d2-36a9-42ef-a824-612b89d61211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_17</th>\n",
       "      <th>ecg_id_18</th>\n",
       "      <th>ecg_id_20</th>\n",
       "      <th>ecg_id_22</th>\n",
       "      <th>ecg_id_23</th>\n",
       "      <th>ecg_id_26</th>\n",
       "      <th>ecg_id_28</th>\n",
       "      <th>ecg_id_30</th>\n",
       "      <th>ecg_id_32</th>\n",
       "      <th>ecg_id_34</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21806</th>\n",
       "      <th>ecg_id_21812</th>\n",
       "      <th>ecg_id_21816</th>\n",
       "      <th>ecg_id_21817</th>\n",
       "      <th>ecg_id_21819</th>\n",
       "      <th>ecg_id_21821</th>\n",
       "      <th>ecg_id_21829</th>\n",
       "      <th>ecg_id_21832</th>\n",
       "      <th>ecg_id_21833</th>\n",
       "      <th>ecg_id_21835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020789</td>\n",
       "      <td>-0.044607</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.014863</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.007912</td>\n",
       "      <td>0.072998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>-0.016424</td>\n",
       "      <td>-0.010705</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.038642</td>\n",
       "      <td>-0.017364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.022534</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.023951</td>\n",
       "      <td>-0.040538</td>\n",
       "      <td>-0.006658</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.123542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>-0.017545</td>\n",
       "      <td>-0.012709</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.040612</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.038123</td>\n",
       "      <td>-0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024929</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.023457</td>\n",
       "      <td>-0.042989</td>\n",
       "      <td>-0.006916</td>\n",
       "      <td>-0.007233</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.008007</td>\n",
       "      <td>0.162820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>-0.040717</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>-0.039146</td>\n",
       "      <td>-0.008225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027371</td>\n",
       "      <td>-0.046922</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.023816</td>\n",
       "      <td>-0.043179</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.006705</td>\n",
       "      <td>-0.007965</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.178342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>-0.041912</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>-0.042718</td>\n",
       "      <td>-0.004455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027478</td>\n",
       "      <td>-0.048258</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.006149</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>-0.008052</td>\n",
       "      <td>-0.008969</td>\n",
       "      <td>0.156886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013407</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>-0.012525</td>\n",
       "      <td>-0.006498</td>\n",
       "      <td>-0.044389</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>-0.048779</td>\n",
       "      <td>-0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.002525</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>-0.021608</td>\n",
       "      <td>-0.004067</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030718</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.002484</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>-0.003760</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027790</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>-0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.002678</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-0.007574</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.018068</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-0.007187</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.016270</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.006690</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>-0.014475</td>\n",
       "      <td>-0.002522</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>-0.000605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 7815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_17  ecg_id_18  ecg_id_20  ecg_id_22  ecg_id_23  ecg_id_26  \\\n",
       "0     -0.020789  -0.044607  -0.001175  -0.025060  -0.037304  -0.005681   \n",
       "1     -0.022534  -0.045078  -0.001420  -0.023951  -0.040538  -0.006658   \n",
       "2     -0.024929  -0.045824  -0.001521  -0.023457  -0.042989  -0.006916   \n",
       "3     -0.027371  -0.046922  -0.001447  -0.023816  -0.043179  -0.006485   \n",
       "4     -0.027478  -0.048258  -0.001239  -0.024972  -0.039306  -0.006149   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4595  -0.002525  -0.008924   0.000351   0.001532  -0.008504   0.002741   \n",
       "4596  -0.002484  -0.008285   0.000323   0.001453  -0.007954   0.002487   \n",
       "4597  -0.002678  -0.007712   0.000286   0.001300  -0.007574   0.002239   \n",
       "4598  -0.003031  -0.007187   0.000244   0.001050  -0.007306   0.002020   \n",
       "4599  -0.003460  -0.006690   0.000200   0.000722  -0.007090   0.001832   \n",
       "\n",
       "      ecg_id_28  ecg_id_30  ecg_id_32  ecg_id_34  ...  ecg_id_21806  \\\n",
       "0     -0.014863  -0.005984  -0.007912   0.072998  ...     -0.004031   \n",
       "1     -0.010334  -0.006977  -0.007887   0.123542  ...     -0.007671   \n",
       "2     -0.007233  -0.007651  -0.008007   0.162820  ...     -0.010359   \n",
       "3     -0.006705  -0.007965  -0.008363   0.178342  ...     -0.012087   \n",
       "4     -0.009506  -0.008052  -0.008969   0.156886  ...     -0.013407   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "4595  -0.021608  -0.004067  -0.000269   0.010352  ...      0.030718   \n",
       "4596  -0.019854  -0.003760  -0.000252   0.010404  ...      0.027790   \n",
       "4597  -0.018068  -0.003398  -0.000239   0.009925  ...      0.024824   \n",
       "4598  -0.016270  -0.002979  -0.000228   0.008690  ...      0.022140   \n",
       "4599  -0.014475  -0.002522  -0.000219   0.006842  ...      0.019799   \n",
       "\n",
       "      ecg_id_21812  ecg_id_21816  ecg_id_21817  ecg_id_21819  ecg_id_21821  \\\n",
       "0         0.003311     -0.002510     -0.016424     -0.010705     -0.006108   \n",
       "1         0.002737     -0.001892     -0.017545     -0.012709     -0.006089   \n",
       "2         0.002675     -0.001150     -0.018455     -0.014036     -0.006124   \n",
       "3         0.003402     -0.000393     -0.018975     -0.014084     -0.006251   \n",
       "4         0.004868     -0.000180     -0.019009     -0.012525     -0.006498   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.000541      0.000917     -0.000884     -0.005866     -0.005420   \n",
       "4596      0.000493      0.000846     -0.000823     -0.005401     -0.004976   \n",
       "4597      0.000436      0.000770     -0.000770     -0.004908     -0.004456   \n",
       "4598      0.000374      0.000692     -0.000722     -0.004397     -0.003888   \n",
       "4599      0.000309      0.000611     -0.000676     -0.003881     -0.003299   \n",
       "\n",
       "      ecg_id_21829  ecg_id_21832  ecg_id_21833  ecg_id_21835  \n",
       "0        -0.041105     -0.005660     -0.038642     -0.017364  \n",
       "1        -0.040612     -0.006637     -0.038123     -0.012750  \n",
       "2        -0.040717     -0.007312     -0.039146     -0.008225  \n",
       "3        -0.041912     -0.007466     -0.042718     -0.004455  \n",
       "4        -0.044389     -0.007023     -0.048779     -0.003396  \n",
       "...            ...           ...           ...           ...  \n",
       "4595     -0.007793      0.005081     -0.008164     -0.001286  \n",
       "4596     -0.007036      0.004661     -0.007511     -0.001148  \n",
       "4597     -0.005838      0.004222     -0.006819     -0.000982  \n",
       "4598     -0.004348      0.003774     -0.006108     -0.000797  \n",
       "4599     -0.002726      0.003325     -0.005394     -0.000605  \n",
       "\n",
       "[4600 rows x 7815 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c17730-f526-4c72-80a3-17c3fa0d656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete any column in which any reading is NaN\n",
    "norm_df = norm_df.dropna(axis=1)\n",
    "mi_df = mi_df.dropna(axis=1)\n",
    "non_mi_df = non_mi_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98374105-1d6a-4a47-9db9-e8b07fcee4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_1</th>\n",
       "      <th>ecg_id_2</th>\n",
       "      <th>ecg_id_3</th>\n",
       "      <th>ecg_id_4</th>\n",
       "      <th>ecg_id_5</th>\n",
       "      <th>ecg_id_6</th>\n",
       "      <th>ecg_id_7</th>\n",
       "      <th>ecg_id_9</th>\n",
       "      <th>ecg_id_10</th>\n",
       "      <th>ecg_id_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21814</th>\n",
       "      <th>ecg_id_21818</th>\n",
       "      <th>ecg_id_21822</th>\n",
       "      <th>ecg_id_21823</th>\n",
       "      <th>ecg_id_21825</th>\n",
       "      <th>ecg_id_21830</th>\n",
       "      <th>ecg_id_21831</th>\n",
       "      <th>ecg_id_21834</th>\n",
       "      <th>ecg_id_21836</th>\n",
       "      <th>ecg_id_21837</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>-0.039000</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.028732</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>-0.021314</td>\n",
       "      <td>-0.039865</td>\n",
       "      <td>0.029101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023012</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.016769</td>\n",
       "      <td>-0.006891</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.007398</td>\n",
       "      <td>-0.006681</td>\n",
       "      <td>-0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012923</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>-0.040540</td>\n",
       "      <td>-0.003672</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.029169</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-0.040053</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023845</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>-0.008623</td>\n",
       "      <td>-0.004408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015592</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-0.004065</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.029958</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.030743</td>\n",
       "      <td>-0.040922</td>\n",
       "      <td>0.034173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.004136</td>\n",
       "      <td>-0.023896</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>-0.015739</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>-0.010028</td>\n",
       "      <td>-0.004711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017107</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>-0.043554</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.030994</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.032745</td>\n",
       "      <td>-0.042824</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024848</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>-0.024516</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>-0.003093</td>\n",
       "      <td>-0.010945</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>-0.044784</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.004724</td>\n",
       "      <td>-0.032476</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024894</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>-0.004322</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.010007</td>\n",
       "      <td>-0.004983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.005493</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>-0.007596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.004969</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.005355</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>-0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>-0.003660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.004574</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>-0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.004258</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>-0.005464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.003666</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>-0.004658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 8938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_1  ecg_id_2  ecg_id_3  ecg_id_4  ecg_id_5  ecg_id_6  ecg_id_7  \\\n",
       "0    -0.009347  0.003970 -0.039000 -0.003108 -0.000459 -0.028732 -0.004423   \n",
       "1    -0.012923  0.004130 -0.040540 -0.003672 -0.000078 -0.029169 -0.004455   \n",
       "2    -0.015592  0.004313 -0.042083 -0.004065  0.000122 -0.029958 -0.004510   \n",
       "3    -0.017107  0.004451 -0.043554 -0.004296  0.000013 -0.030994 -0.004599   \n",
       "4    -0.017702  0.004352 -0.044784 -0.004461 -0.000443 -0.031639 -0.004724   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4595  0.005499 -0.000025 -0.005809 -0.003973 -0.000129  0.003427 -0.000903   \n",
       "4596  0.004969 -0.000020 -0.005355 -0.003513 -0.000112  0.003118 -0.000827   \n",
       "4597  0.004487  0.000015 -0.004830 -0.002628 -0.000100  0.002773 -0.000746   \n",
       "4598  0.004102  0.000069 -0.004258 -0.001457 -0.000090  0.002404 -0.000664   \n",
       "4599  0.003807  0.000131 -0.003666 -0.000155 -0.000081  0.002027 -0.000581   \n",
       "\n",
       "      ecg_id_9  ecg_id_10  ecg_id_11  ...  ecg_id_21814  ecg_id_21818  \\\n",
       "0    -0.021314  -0.039865   0.029101  ...     -0.023012     -0.001422   \n",
       "1    -0.026685  -0.040053   0.031884  ...     -0.023845     -0.001576   \n",
       "2    -0.030743  -0.040922   0.034173  ...     -0.024496     -0.001693   \n",
       "3    -0.032745  -0.042824   0.035931  ...     -0.024848     -0.001744   \n",
       "4    -0.032476  -0.045653   0.037407  ...     -0.024894     -0.001723   \n",
       "...        ...        ...        ...  ...           ...           ...   \n",
       "4595  0.001467  -0.001330  -0.004544  ...     -0.000153     -0.003259   \n",
       "4596  0.001179  -0.001239  -0.004117  ...     -0.000156     -0.002987   \n",
       "4597  0.001030  -0.001149  -0.003660  ...     -0.000158     -0.002663   \n",
       "4598  0.001095  -0.001061  -0.003228  ...     -0.000160     -0.002303   \n",
       "4599  0.001340  -0.000972  -0.002839  ...     -0.000163     -0.001929   \n",
       "\n",
       "      ecg_id_21822  ecg_id_21823  ecg_id_21825  ecg_id_21830  ecg_id_21831  \\\n",
       "0        -0.003744     -0.021490     -0.016769     -0.006891     -0.002969   \n",
       "1        -0.003956     -0.022829     -0.012274     -0.011858     -0.003013   \n",
       "2        -0.004136     -0.023896     -0.008044     -0.015739     -0.003054   \n",
       "3        -0.004260     -0.024516     -0.004839     -0.017761     -0.003093   \n",
       "4        -0.004322     -0.024624     -0.004421     -0.017430     -0.003139   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.001467     -0.001109     -0.001520      0.000290     -0.005493   \n",
       "4596      0.001340     -0.001026     -0.001357      0.000260     -0.005039   \n",
       "4597      0.001202     -0.000937     -0.001185      0.000295     -0.004574   \n",
       "4598      0.001057     -0.000844     -0.001008      0.000377     -0.004103   \n",
       "4599      0.000908     -0.000748     -0.000831      0.000483     -0.003630   \n",
       "\n",
       "      ecg_id_21834  ecg_id_21836  ecg_id_21837  \n",
       "0        -0.007398     -0.006681     -0.004043  \n",
       "1        -0.009197     -0.008623     -0.004408  \n",
       "2        -0.010527     -0.010028     -0.004711  \n",
       "3        -0.010945     -0.010549     -0.004907  \n",
       "4        -0.010145     -0.010007     -0.004983  \n",
       "...            ...           ...           ...  \n",
       "4595      0.000944      0.004262     -0.007596  \n",
       "4596      0.000856      0.003903     -0.006966  \n",
       "4597      0.000773      0.003509     -0.006244  \n",
       "4598      0.000695      0.003093     -0.005464  \n",
       "4599      0.000619      0.002671     -0.004658  \n",
       "\n",
       "[4600 rows x 8938 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705c4453-7e80-4268-93fe-77b8558e6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_77</th>\n",
       "      <th>ecg_id_106</th>\n",
       "      <th>ecg_id_131</th>\n",
       "      <th>ecg_id_139</th>\n",
       "      <th>ecg_id_152</th>\n",
       "      <th>ecg_id_162</th>\n",
       "      <th>ecg_id_177</th>\n",
       "      <th>ecg_id_181</th>\n",
       "      <th>ecg_id_184</th>\n",
       "      <th>ecg_id_189</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21788</th>\n",
       "      <th>ecg_id_21793</th>\n",
       "      <th>ecg_id_21796</th>\n",
       "      <th>ecg_id_21799</th>\n",
       "      <th>ecg_id_21805</th>\n",
       "      <th>ecg_id_21811</th>\n",
       "      <th>ecg_id_21815</th>\n",
       "      <th>ecg_id_21826</th>\n",
       "      <th>ecg_id_21827</th>\n",
       "      <th>ecg_id_21828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038216</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.018618</td>\n",
       "      <td>-0.024321</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>-0.007663</td>\n",
       "      <td>-0.032769</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.353304</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.019221</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>-0.028041</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>-0.009266</td>\n",
       "      <td>-0.032548</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.021936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.360804</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.020913</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>-0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039715</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.019885</td>\n",
       "      <td>-0.030967</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>-0.032718</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.022117</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>-0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040454</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.020368</td>\n",
       "      <td>-0.032966</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.010664</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>0.396816</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>-0.022629</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>-0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040977</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>-0.034439</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.034861</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>0.438201</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>-0.022710</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>-0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>-0.008708</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018354</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.007124</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.006392</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.006327</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.001831</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>-0.002459</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 4145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_77  ecg_id_106  ecg_id_131  ecg_id_139  ecg_id_152  ecg_id_162  \\\n",
       "0     -0.038216   -0.000989   -0.018618   -0.024321   -0.004008    0.004239   \n",
       "1     -0.038924   -0.000582   -0.019282   -0.028041   -0.004006    0.004611   \n",
       "2     -0.039715   -0.000276   -0.019885   -0.030967   -0.003715    0.004879   \n",
       "3     -0.040454   -0.000139   -0.020368   -0.032966   -0.002968    0.004980   \n",
       "4     -0.040977   -0.000192   -0.020707   -0.034439   -0.001936    0.004937   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "4595  -0.000371   -0.003030   -0.001336   -0.012455    0.003633    0.000759   \n",
       "4596  -0.000364   -0.002777   -0.001236   -0.011647    0.003335    0.000700   \n",
       "4597  -0.000373   -0.002482   -0.001112   -0.010651    0.003025    0.000636   \n",
       "4598  -0.000401   -0.002162   -0.000973   -0.009366    0.002709    0.000570   \n",
       "4599  -0.000443   -0.001831   -0.000828   -0.007837    0.002391    0.000503   \n",
       "\n",
       "      ecg_id_177  ecg_id_181  ecg_id_184  ecg_id_189  ...  ecg_id_21788  \\\n",
       "0      -0.007663   -0.032769    0.008102    0.020674  ...     -0.003852   \n",
       "1      -0.009266   -0.032548    0.006741    0.021936  ...     -0.003325   \n",
       "2      -0.010420   -0.032718    0.005921    0.022862  ...     -0.003049   \n",
       "3      -0.010664   -0.033484    0.005843    0.023257  ...     -0.003045   \n",
       "4      -0.009600   -0.034861    0.006418    0.023114  ...     -0.003172   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "4595   -0.008535   -0.007130   -0.004652    0.002573  ...     -0.020067   \n",
       "4596   -0.007842   -0.006564   -0.004190    0.002382  ...     -0.018354   \n",
       "4597   -0.007124   -0.005976   -0.003465    0.002184  ...     -0.016345   \n",
       "4598   -0.006392   -0.005377   -0.002566    0.001982  ...     -0.014145   \n",
       "4599   -0.005655   -0.004774   -0.001587    0.001780  ...     -0.011864   \n",
       "\n",
       "      ecg_id_21793  ecg_id_21796  ecg_id_21799  ecg_id_21805  ecg_id_21811  \\\n",
       "0         0.353304      0.013632      0.012455      0.000497     -0.019221   \n",
       "1         0.360804      0.014458      0.013331      0.000873     -0.020913   \n",
       "2         0.373210      0.015139      0.014043      0.001158     -0.022117   \n",
       "3         0.396816      0.015568      0.014469      0.001291     -0.022629   \n",
       "4         0.438201      0.015712      0.014571      0.001255     -0.022710   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.009014     -0.000256      0.002257     -0.003724     -0.008708   \n",
       "4596      0.009014     -0.000223      0.002080     -0.003414     -0.007997   \n",
       "4597      0.008317     -0.000192      0.001892     -0.003097     -0.007192   \n",
       "4598      0.006642     -0.000162      0.001700     -0.002778     -0.006327   \n",
       "4599      0.004176     -0.000134      0.001505     -0.002459     -0.005438   \n",
       "\n",
       "      ecg_id_21815  ecg_id_21826  ecg_id_21827  ecg_id_21828  \n",
       "0         0.005553      0.011715      0.010180     -0.001342  \n",
       "1         0.006690      0.011091      0.010963     -0.001450  \n",
       "2         0.008079      0.010091      0.011743     -0.001540  \n",
       "3         0.009693      0.008625      0.012379     -0.001597  \n",
       "4         0.011035      0.007408      0.012609     -0.001618  \n",
       "...            ...           ...           ...           ...  \n",
       "4595      0.002847      0.001047      0.000090      0.001465  \n",
       "4596      0.002616      0.000958      0.000097      0.001339  \n",
       "4597      0.002389      0.000856      0.000102      0.001210  \n",
       "4598      0.002166      0.000748      0.000105      0.001079  \n",
       "4599      0.001945      0.000636      0.000109      0.000947  \n",
       "\n",
       "[4600 rows x 4145 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35738de9-ac1c-4976-8839-66b8289925d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_17</th>\n",
       "      <th>ecg_id_18</th>\n",
       "      <th>ecg_id_20</th>\n",
       "      <th>ecg_id_22</th>\n",
       "      <th>ecg_id_23</th>\n",
       "      <th>ecg_id_26</th>\n",
       "      <th>ecg_id_28</th>\n",
       "      <th>ecg_id_30</th>\n",
       "      <th>ecg_id_32</th>\n",
       "      <th>ecg_id_34</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21806</th>\n",
       "      <th>ecg_id_21812</th>\n",
       "      <th>ecg_id_21816</th>\n",
       "      <th>ecg_id_21817</th>\n",
       "      <th>ecg_id_21819</th>\n",
       "      <th>ecg_id_21821</th>\n",
       "      <th>ecg_id_21829</th>\n",
       "      <th>ecg_id_21832</th>\n",
       "      <th>ecg_id_21833</th>\n",
       "      <th>ecg_id_21835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020789</td>\n",
       "      <td>-0.044607</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.014863</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.007912</td>\n",
       "      <td>0.072998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>-0.016424</td>\n",
       "      <td>-0.010705</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.038642</td>\n",
       "      <td>-0.017364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.022534</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.023951</td>\n",
       "      <td>-0.040538</td>\n",
       "      <td>-0.006658</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.123542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>-0.017545</td>\n",
       "      <td>-0.012709</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.040612</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.038123</td>\n",
       "      <td>-0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024929</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.023457</td>\n",
       "      <td>-0.042989</td>\n",
       "      <td>-0.006916</td>\n",
       "      <td>-0.007233</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.008007</td>\n",
       "      <td>0.162820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>-0.040717</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>-0.039146</td>\n",
       "      <td>-0.008225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027371</td>\n",
       "      <td>-0.046922</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.023816</td>\n",
       "      <td>-0.043179</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.006705</td>\n",
       "      <td>-0.007965</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.178342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>-0.041912</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>-0.042718</td>\n",
       "      <td>-0.004455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027478</td>\n",
       "      <td>-0.048258</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.006149</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>-0.008052</td>\n",
       "      <td>-0.008969</td>\n",
       "      <td>0.156886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013407</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>-0.012525</td>\n",
       "      <td>-0.006498</td>\n",
       "      <td>-0.044389</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>-0.048779</td>\n",
       "      <td>-0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.002525</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>-0.021608</td>\n",
       "      <td>-0.004067</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030718</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.002484</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>-0.003760</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027790</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>-0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.002678</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-0.007574</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.018068</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-0.007187</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.016270</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.006690</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>-0.014475</td>\n",
       "      <td>-0.002522</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>-0.000605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 7815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_17  ecg_id_18  ecg_id_20  ecg_id_22  ecg_id_23  ecg_id_26  \\\n",
       "0     -0.020789  -0.044607  -0.001175  -0.025060  -0.037304  -0.005681   \n",
       "1     -0.022534  -0.045078  -0.001420  -0.023951  -0.040538  -0.006658   \n",
       "2     -0.024929  -0.045824  -0.001521  -0.023457  -0.042989  -0.006916   \n",
       "3     -0.027371  -0.046922  -0.001447  -0.023816  -0.043179  -0.006485   \n",
       "4     -0.027478  -0.048258  -0.001239  -0.024972  -0.039306  -0.006149   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4595  -0.002525  -0.008924   0.000351   0.001532  -0.008504   0.002741   \n",
       "4596  -0.002484  -0.008285   0.000323   0.001453  -0.007954   0.002487   \n",
       "4597  -0.002678  -0.007712   0.000286   0.001300  -0.007574   0.002239   \n",
       "4598  -0.003031  -0.007187   0.000244   0.001050  -0.007306   0.002020   \n",
       "4599  -0.003460  -0.006690   0.000200   0.000722  -0.007090   0.001832   \n",
       "\n",
       "      ecg_id_28  ecg_id_30  ecg_id_32  ecg_id_34  ...  ecg_id_21806  \\\n",
       "0     -0.014863  -0.005984  -0.007912   0.072998  ...     -0.004031   \n",
       "1     -0.010334  -0.006977  -0.007887   0.123542  ...     -0.007671   \n",
       "2     -0.007233  -0.007651  -0.008007   0.162820  ...     -0.010359   \n",
       "3     -0.006705  -0.007965  -0.008363   0.178342  ...     -0.012087   \n",
       "4     -0.009506  -0.008052  -0.008969   0.156886  ...     -0.013407   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "4595  -0.021608  -0.004067  -0.000269   0.010352  ...      0.030718   \n",
       "4596  -0.019854  -0.003760  -0.000252   0.010404  ...      0.027790   \n",
       "4597  -0.018068  -0.003398  -0.000239   0.009925  ...      0.024824   \n",
       "4598  -0.016270  -0.002979  -0.000228   0.008690  ...      0.022140   \n",
       "4599  -0.014475  -0.002522  -0.000219   0.006842  ...      0.019799   \n",
       "\n",
       "      ecg_id_21812  ecg_id_21816  ecg_id_21817  ecg_id_21819  ecg_id_21821  \\\n",
       "0         0.003311     -0.002510     -0.016424     -0.010705     -0.006108   \n",
       "1         0.002737     -0.001892     -0.017545     -0.012709     -0.006089   \n",
       "2         0.002675     -0.001150     -0.018455     -0.014036     -0.006124   \n",
       "3         0.003402     -0.000393     -0.018975     -0.014084     -0.006251   \n",
       "4         0.004868     -0.000180     -0.019009     -0.012525     -0.006498   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.000541      0.000917     -0.000884     -0.005866     -0.005420   \n",
       "4596      0.000493      0.000846     -0.000823     -0.005401     -0.004976   \n",
       "4597      0.000436      0.000770     -0.000770     -0.004908     -0.004456   \n",
       "4598      0.000374      0.000692     -0.000722     -0.004397     -0.003888   \n",
       "4599      0.000309      0.000611     -0.000676     -0.003881     -0.003299   \n",
       "\n",
       "      ecg_id_21829  ecg_id_21832  ecg_id_21833  ecg_id_21835  \n",
       "0        -0.041105     -0.005660     -0.038642     -0.017364  \n",
       "1        -0.040612     -0.006637     -0.038123     -0.012750  \n",
       "2        -0.040717     -0.007312     -0.039146     -0.008225  \n",
       "3        -0.041912     -0.007466     -0.042718     -0.004455  \n",
       "4        -0.044389     -0.007023     -0.048779     -0.003396  \n",
       "...            ...           ...           ...           ...  \n",
       "4595     -0.007793      0.005081     -0.008164     -0.001286  \n",
       "4596     -0.007036      0.004661     -0.007511     -0.001148  \n",
       "4597     -0.005838      0.004222     -0.006819     -0.000982  \n",
       "4598     -0.004348      0.003774     -0.006108     -0.000797  \n",
       "4599     -0.002726      0.003325     -0.005394     -0.000605  \n",
       "\n",
       "[4600 rows x 7815 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "285d5892-07e8-4a68-8f1f-a4bdf2e4de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the order of the ecg recordings\n",
    "import random\n",
    "norm_cols = norm_df.columns.to_list()\n",
    "random.shuffle(norm_cols)\n",
    "mi_cols = mi_df.columns.to_list()\n",
    "random.shuffle(mi_cols)\n",
    "non_mi_cols = non_mi_df.columns.to_list()\n",
    "random.shuffle(non_mi_cols)\n",
    "norm_df = norm_df[norm_cols]\n",
    "mi_df = mi_df[mi_cols]\n",
    "non_mi_df = non_mi_df[non_mi_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d9314d-963b-4b6b-bf79-a8437bd20447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of norm cases: \n",
      "8938\n",
      "Number of MI cases: \n",
      "4145\n",
      "Number of non_MI cases: \n",
      "7815\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of norm cases: \")\n",
    "print(len(norm_df.columns))\n",
    "print(\"Number of MI cases: \")\n",
    "print(len(mi_df.columns))\n",
    "print(\"Number of non_MI cases: \")\n",
    "print(len(non_mi_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4d68c85-1ab6-4e32-bd91-ed062cee8333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4107, 8, 230, 1)\n",
      "(8873, 8, 230, 1)\n",
      "(7768, 8, 230, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "beat_len = 230\n",
    "\n",
    "mi_beats = []\n",
    "for ecg in mi_df.columns:\n",
    "    _mi_beats = []\n",
    "    peaks = apply_pan_tompkins(mi_df[ecg], n_beats=8, right_data=0.25)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak].to_numpy()\n",
    "        #print(np.shape(p)[0])\n",
    "        \n",
    "        # TODO(simona): For some reason, sometimes it does not return beats of the same length, fix this in the code\n",
    "        if np.shape(p)[0] != beat_len: continue\n",
    "        \n",
    "        ## Min max scale after detecting beat\n",
    "        # p = np.reshape(p, [-1, 1])\n",
    "        # p = scaler.fit_transform(p)\n",
    "        _mi_beats.append(p)\n",
    "        \n",
    "    _mi_beats = np.array(_mi_beats)\n",
    "    \n",
    "    # TODO(simona): For some reason, the pan tompkins does not always return n_beats, fix this in the code\n",
    "    if np.shape(_mi_beats)[0] == 8:\n",
    "        # Shuffle sequence of beats\n",
    "        df = pd.DataFrame(np.reshape(_mi_beats, [8,beat_len]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _mi_beats = df.to_numpy()\n",
    "        _mi_beats = np.reshape(_mi_beats, [8,beat_len,1])\n",
    "        mi_beats.append(_mi_beats)\n",
    "\n",
    "norm_beats = []\n",
    "for ecg in norm_df.columns:\n",
    "    _norm_beats = []\n",
    "    peaks = apply_pan_tompkins(norm_df[ecg], n_beats=8, right_data=0.25)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak].to_numpy()\n",
    "        \n",
    "        # TODO(simona): For some reason, sometimes it does not return beats of the same length, fix this in the code\n",
    "        if np.shape(p)[0] != beat_len: continue\n",
    "        \n",
    "        ## Min max scale after detecting beat\n",
    "        # p = np.reshape(p, [-1, 1])\n",
    "        # p = scaler.fit_transform(p)\n",
    "        _norm_beats.append(p)\n",
    "    \n",
    "    _norm_beats = np.array(_norm_beats)\n",
    "    \n",
    "    # TODO(simona): For some reason, the pan tompkins does not always return n_beats, fix this in the code\n",
    "    if np.shape(_norm_beats)[0] == 8:\n",
    "        df = pd.DataFrame(np.reshape(_norm_beats, [8,beat_len]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _norm_beats = df.to_numpy()\n",
    "        _norm_beats = np.reshape(_norm_beats, [8,beat_len,1])\n",
    "        norm_beats.append(_norm_beats)\n",
    "        \n",
    "non_mi_beats = []\n",
    "for ecg in non_mi_df.columns:\n",
    "    _non_mi_beats = []\n",
    "    peaks = apply_pan_tompkins(non_mi_df[ecg], n_beats=8, right_data=0.25)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak].to_numpy()\n",
    "        \n",
    "        # TODO(simona): For some reason, sometimes it does not return beats of the same length, fix this in the code\n",
    "        if np.shape(p)[0] != beat_len: continue\n",
    "        \n",
    "        ## Min max scale after detecting beat\n",
    "        # p = np.reshape(p, [-1, 1])\n",
    "        # p = scaler.fit_transform(p)\n",
    "        _non_mi_beats.append(p)\n",
    "   \n",
    "    _non_mi_beats = np.array(_non_mi_beats)\n",
    "    \n",
    "    # TODO(simona): For some reason, the pan tompkins does not always return n_beats, fix this in the code\n",
    "    if np.shape(_non_mi_beats)[0] == 8:\n",
    "        df = pd.DataFrame(np.reshape(_non_mi_beats, [8,beat_len]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _non_mi_beats = df.to_numpy()\n",
    "        _non_mi_beats = np.reshape(_non_mi_beats, [8,beat_len,1])\n",
    "        non_mi_beats.append(_non_mi_beats)\n",
    "    \n",
    "print(np.shape(mi_beats))\n",
    "print(np.shape(norm_beats))\n",
    "print(np.shape(non_mi_beats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "855e1d75-3de3-4791-9844-a85c1602b590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1000):\n",
    "    plt.plot(norm_beats[i][1])\n",
    "#plt.plot(mi_beats[2000][1])\n",
    "# plt.plot(mi_beats[2001][1])\n",
    "# plt.plot(mi_beats[2002][1])\n",
    "# plt.plot(mi_beats[2003][1])\n",
    "# plt.plot(mi_beats[2004][1])\n",
    "# plt.plot(mi_beats[2005][1])\n",
    "# plt.plot(mi_beats[2006][1])\n",
    "# plt.plot(mi_beats[2007][1])\n",
    "# plt.plot(mi_beats[2008][1])\n",
    "# plt.plot(mi_beats[2009][1])\n",
    "# plt.plot(mi_beats[2010][1])\n",
    "# plt.plot(mi_beats[2011][1])\n",
    "# plt.plot(mi_beats[2012][1])\n",
    "# plt.plot(mi_beats[2013][1])\n",
    "# plt.plot(mi_beats[2014][1])\n",
    "# plt.plot(mi_beats[2015][1])\n",
    "# plt.plot(mi_beats[2016][1])\n",
    "# plt.plot(mi_beats[2017][1])\n",
    "# plt.plot(mi_beats[2018][1])\n",
    "# plt.plot(mi_beats[2019][1])\n",
    "plt.show()\n",
    "#mi_beats[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa22531-7ac2-4600-b948-6e157ef9ede9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1644, 1238]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16312/1106144146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Shuffle across the first index using the same logic for both the label and the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel_1_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1_labels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1_labels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel_1_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1_labels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1_labels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(random_state, n_samples, *arrays)\u001b[0m\n\u001b[1;32m    667\u001b[0m     \"\"\"\n\u001b[1;32m    668\u001b[0m     return resample(\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m     )\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[1;32m    552\u001b[0m         )\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    331\u001b[0m         raise ValueError(\n\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1644, 1238]"
     ]
    }
   ],
   "source": [
    "# We are going to make three training and testing sets for each of the models.\n",
    "# We will then use these datasets to train each of the individual one-vs-one classifiers\n",
    "# For each of these datasets, we want a balanced of classes, such that a good classifier can be made.\n",
    "# After, we will then make a 4th dataset to train the meta classifier, without updating the weights of the individual ovo models\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Dataset for model 1: MI vs non-MI model\n",
    "\n",
    "# Separate into train and test set with balanced class labels\n",
    "model_1_data_train = np.concatenate((mi_beats[0:int(0.8*len(mi_beats))], non_mi_beats[0:int(0.8*len(mi_beats))]))\n",
    "model_1_data_test = np.concatenate((mi_beats[int(0.8*len(mi_beats)):], non_mi_beats[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Class labels: MI - 1, non-MI - 0\n",
    "mi_label_model_1 = np.ones((3904,1,1))\n",
    "non_mi_label_model_1 = np.zeros((3904,1,1))\n",
    "\n",
    "model_1_labels_train = np.concatenate((mi_label_model_1[0:int(0.8*len(mi_beats))], non_mi_label_model_1[0:int(0.8*len(mi_beats))]))\n",
    "model_1_labels_test = np.concatenate((mi_label_model_1[int(0.8*len(mi_beats)):], non_mi_label_model_1[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_1_data_train, model_1_labels_train = shuffle(model_1_data_train, model_1_labels_train, random_state=42)\n",
    "model_1_data_test, model_1_labels_test = shuffle(model_1_data_test, model_1_labels_test, random_state=42)\n",
    "\n",
    "print(np.shape(model_1_data_train))\n",
    "print(np.shape(model_1_labels_train))\n",
    "\n",
    "print(np.shape(model_1_data_test))\n",
    "print(np.shape(model_1_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac79d6-ffc7-43e8-8417-fdeeaa5d5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3904):\n",
    "    plt.plot(mi_beats[i][0]);\n",
    "    plt.plot(mi_beats[i][1]);\n",
    "    plt.plot(mi_beats[i][2]);\n",
    "    plt.plot(mi_beats[i][3]);\n",
    "    plt.plot(mi_beats[i][4]);\n",
    "    plt.plot(mi_beats[i][5]);\n",
    "    plt.plot(mi_beats[i][6]);\n",
    "    plt.plot(mi_beats[i][7]);\n",
    "plt.show()\n",
    "\n",
    "for i in range(3904):\n",
    "    plt.plot(non_mi_beats[i][1]);\n",
    "plt.show()\n",
    "\n",
    "for i in range(3904):\n",
    "    plt.plot(norm_beats[i][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb953b-38d6-414c-a9c3-462f00a1a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for model 2: MI vs norm model\n",
    "\n",
    "# Separate into training and testing set\n",
    "model_2_data_train = np.concatenate((mi_beats[0:int(0.8*len(mi_beats))], norm_beats[0:int(0.8*len(mi_beats))]))\n",
    "model_2_data_test = np.concatenate((mi_beats[int(0.8*len(mi_beats)):], norm_beats[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Class labels: MI - 1, norm - 0\n",
    "mi_label_model_2 = np.ones((3904,1,1))\n",
    "norm_label_model_2 = np.zeros((3904,1,1))\n",
    "\n",
    "model_2_labels_train = np.concatenate((mi_label_model_2[0:int(0.8*len(mi_beats))], norm_label_model_2[0:int(0.8*len(mi_beats))]))\n",
    "model_2_labels_test = np.concatenate((mi_label_model_2[int(0.8*len(mi_beats)):], norm_label_model_2[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_2_data_train, model_2_labels_train = shuffle(model_2_data_train, model_2_labels_train, random_state=42)\n",
    "model_2_data_test, model_2_labels_test = shuffle(model_2_data_test, model_2_labels_test, random_state=42)\n",
    "\n",
    "print(np.shape(model_2_data_train))\n",
    "print(np.shape(model_2_labels_train))\n",
    "\n",
    "print(np.shape(model_2_data_test))\n",
    "print(np.shape(model_2_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104eb2d4-0f35-4155-ab93-e13688c515c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for model 3: non-MI vs norm model\n",
    "\n",
    "# Separate into training and testing set\n",
    "model_3_data_train = np.concatenate((non_mi_beats[0:int(0.8*len(non_mi_beats))], norm_beats[0:int(0.8*len(non_mi_beats))]))\n",
    "model_3_data_test = np.concatenate((non_mi_beats[int(0.8*len(non_mi_beats)):], norm_beats[int(0.8*len(non_mi_beats)):len(non_mi_beats)]))\n",
    "\n",
    "# Class labels: non-MI - 0, norm - 1\n",
    "non_mi_label_model_3 = np.zeros((7412,1,1))\n",
    "norm_label_model_3 = np.ones((7412,1,1))\n",
    "\n",
    "model_3_labels_train = np.concatenate((non_mi_label_model_3[0:int(0.8*len(non_mi_beats))], norm_label_model_3[0:int(0.8*len(non_mi_beats))]))\n",
    "model_3_labels_test = np.concatenate((non_mi_label_model_3[int(0.8*len(non_mi_beats)):], norm_label_model_3[int(0.8*len(non_mi_beats)):len(non_mi_beats)]))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_3_data_train, model_3_labels_train = shuffle(model_3_data_train, model_3_labels_train, random_state=42)\n",
    "model_3_data_test, model_3_labels_test = shuffle(model_3_data_test, model_3_labels_test, random_state=42)\n",
    "\n",
    "print(np.shape(model_3_data_train))\n",
    "print(np.shape(model_3_labels_train))\n",
    "\n",
    "print(np.shape(model_3_data_test))\n",
    "print(np.shape(model_3_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb7220-6b61-4b0a-b772-1b90532a7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for model 4: meta learner - whole dataset\n",
    "\n",
    "# Separate into train and test set with balanced class labels\n",
    "model_4_data_train = np.concatenate((mi_beats[0:int(0.8*len(mi_beats))], non_mi_beats[0:int(0.8*len(mi_beats))], norm_beats[0:int(0.8*len(mi_beats))]))\n",
    "model_4_data_test = np.concatenate((mi_beats[int(0.8*len(mi_beats)):], non_mi_beats[int(0.8*len(mi_beats)):len(mi_beats)], norm_beats[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Class labels: MI - [1,0,0], non-MI - [0,1,0], norm - [0,0,1]\n",
    "mi_label_model_4 = np.zeros((3904,1,3))\n",
    "non_mi_label_model_4 = np.zeros((3904,1,3))\n",
    "norm_label_model_4 = np.zeros((3904,1,3))\n",
    "\n",
    "for i in range(len(mi_label_model_4)):\n",
    "    mi_label_model_4[i] = [1,0,0]\n",
    "    non_mi_label_model_4[i] = [0,1,0]\n",
    "    norm_label_model_4[i] = [0,0,1]\n",
    "\n",
    "model_4_labels_train = np.concatenate((mi_label_model_4[0:int(0.8*len(mi_beats))], non_mi_label_model_4[0:int(0.8*len(mi_beats))], norm_label_model_4[0:int(0.8*len(mi_beats))]))\n",
    "model_4_labels_test = np.concatenate((mi_label_model_4[int(0.8*len(mi_beats)):], non_mi_label_model_4[int(0.8*len(mi_beats)):len(mi_beats)], norm_label_model_4[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_4_data_train, model_4_labels_train = shuffle(model_4_data_train, model_4_labels_train, random_state=42)\n",
    "model_4_data_test, model_4_labels_test = shuffle(model_4_data_test, model_4_labels_test, random_state=42)\n",
    "\n",
    "print(np.shape(model_4_data_train))\n",
    "print(np.shape(model_4_labels_train))\n",
    "\n",
    "print(np.shape(model_4_data_test))\n",
    "print(np.shape(model_4_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704561c4-be91-4b15-b9c3-89c1ca17b65c",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138068a-c464-4c42-a712-4955f015e044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "seq_length = 8\n",
    "beat_length = beat_len\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(seq_length, beat_length, num_feats))\n",
    "\n",
    "## Layers 1-6 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(input)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 7-12 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 13-19 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 19-24 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(12, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layer 25 - time-distributed flatten\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "## Layer 26 - time-distributed dense\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(12, activation='relu'))(x)\n",
    "\n",
    "## Layer 27 - time-distributed batch norm\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "\n",
    "## Layer 28 - time-distributed dropout\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layer 29 - LSTM\n",
    "x = tf.keras.layers.LSTM(12)(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(4, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model_1 = tf.keras.Model(input, output, name=\"cnn_lstm_model_1\")\n",
    "cnn_lstm_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f158bb-7ac1-4126-b1ef-44948abaec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model_1.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7da94-49f9-4dfa-9e57-a9d1ddf676db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "cnn_lstm_model_1.fit(x=model_1_data_train, y=model_1_labels_train, validation_data=[model_1_data_test, model_1_labels_test], batch_size=32, epochs=50, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb511e0-8980-486c-97a6-0cac284d775e",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29c28ed5-6dbd-41f3-b385-37e1c0fe03f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_lstm_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8, 345, 1)]       0         \n",
      "                                                                 \n",
      " time_distributed_84 (TimeDi  (None, 8, 345, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_85 (TimeDi  (None, 8, 345, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_86 (TimeDi  (None, 8, 345, 32)       3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_87 (TimeDi  (None, 8, 345, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_88 (TimeDi  (None, 8, 172, 32)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_89 (TimeDi  (None, 8, 172, 32)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_90 (TimeDi  (None, 8, 172, 32)       3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_91 (TimeDi  (None, 8, 172, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_92 (TimeDi  (None, 8, 172, 32)       3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_93 (TimeDi  (None, 8, 172, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_94 (TimeDi  (None, 8, 86, 32)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_95 (TimeDi  (None, 8, 86, 32)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_96 (TimeDi  (None, 8, 86, 32)        3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_97 (TimeDi  (None, 8, 86, 32)        128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_98 (TimeDi  (None, 8, 86, 32)        3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_99 (TimeDi  (None, 8, 86, 32)        128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_100 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_101 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_102 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_103 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_104 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_105 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_106 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_107 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_108 (TimeD  (None, 8, 672)           0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_109 (TimeD  (None, 8, 32)            21536     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_110 (TimeD  (None, 8, 32)            128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_111 (TimeD  (None, 8, 32)            0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,601\n",
      "Trainable params: 52,929\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "beat_length = 345\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(seq_length, beat_length, num_feats))\n",
    "\n",
    "## Layers 1-6 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(input)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 7-12 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 13-19 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 19-24 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layer 25 - time-distributed flatten\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "## Layer 26 - time-distributed dense\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu'))(x)\n",
    "\n",
    "## Layer 27 - time-distributed batch norm\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "\n",
    "## Layer 28 - time-distributed dropout\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layer 29 - LSTM\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model_2 = tf.keras.Model(input, output, name=\"cnn_lstm_model_2\")\n",
    "cnn_lstm_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dbbe9b1-ea26-43f8-869e-8394da56d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model_2.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83c5585f-c249-4aae-8618-3e3c0488c6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "184/184 [==============================] - 58s 273ms/step - loss: 0.5854 - binary_accuracy: 0.5000 - val_loss: 0.7433 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "184/184 [==============================] - 48s 262ms/step - loss: 0.4632 - binary_accuracy: 0.5000 - val_loss: 0.6859 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb73d495890>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm_model_2.fit(x=model_2_data_train, y=model_2_labels_train, validation_data=[model_2_data_test, model_2_labels_test], batch_size=32, epochs=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ce2997c-d311-4536-aa25-3cea50d78991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_lstm_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8, 345, 1)]       0         \n",
      "                                                                 \n",
      " time_distributed_140 (TimeD  (None, 8, 345, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_141 (TimeD  (None, 8, 345, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_142 (TimeD  (None, 8, 345, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_143 (TimeD  (None, 8, 345, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_144 (TimeD  (None, 8, 172, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_145 (TimeD  (None, 8, 172, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_146 (TimeD  (None, 8, 172, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_147 (TimeD  (None, 8, 172, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_148 (TimeD  (None, 8, 172, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_149 (TimeD  (None, 8, 172, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_150 (TimeD  (None, 8, 86, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_151 (TimeD  (None, 8, 86, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_152 (TimeD  (None, 8, 86, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_153 (TimeD  (None, 8, 86, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_154 (TimeD  (None, 8, 86, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_155 (TimeD  (None, 8, 86, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_156 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_157 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_158 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_159 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_160 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_161 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_162 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_163 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_164 (TimeD  (None, 8, 672)           0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_165 (TimeD  (None, 8, 32)            21536     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_166 (TimeD  (None, 8, 32)            128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_167 (TimeD  (None, 8, 32)            0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,601\n",
      "Trainable params: 52,929\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "beat_length = 345\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(seq_length, beat_length, num_feats))\n",
    "\n",
    "## Layers 1-6 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(input)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 7-12 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 13-19 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layers 19-24 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layer 25 - time-distributed flatten\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "## Layer 26 - time-distributed dense\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu'))(x)\n",
    "\n",
    "## Layer 27 - time-distributed batch norm\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "\n",
    "## Layer 28 - time-distributed dropout\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.2))(x)\n",
    "\n",
    "## Layer 29 - LSTM\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model_3 = tf.keras.Model(input, output, name=\"cnn_lstm_model_3\")\n",
    "cnn_lstm_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f94b594-e533-435a-933a-05e09c37c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model_3.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ace8ee3-a6c4-4323-84a0-b8c0aee11def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "353/353 [==============================] - 98s 258ms/step - loss: 0.5851 - binary_accuracy: 0.5000 - val_loss: 0.5710 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "353/353 [==============================] - 91s 257ms/step - loss: 0.4927 - binary_accuracy: 0.5000 - val_loss: 0.4787 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb73d0769d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm_model_3.fit(x=model_3_data_train, y=model_3_labels_train, validation_data=[model_3_data_test, model_3_labels_test], batch_size=32, epochs=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6274a58-a243-4f85-a788-ffd7f576e906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
