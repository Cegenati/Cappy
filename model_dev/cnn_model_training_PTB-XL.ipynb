{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2906d21-ee68-4a7c-ada3-04e323b205b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading data\n",
    "import os\n",
    "os.environ[\"PTB_FOLDER_PATH\"] = \"/home/jupyter/data/files/ptbdb/1.0.0/\"\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/jupyter/Cappy/ptd_data_handler\")\n",
    "sys.path.insert(0,\"/home/jupyter/Cappy/signal_processing\")\n",
    "from ptb_data_formatter import *\n",
    "from feature_extraction import *\n",
    "from custom_processing import *\n",
    "#all_patient_data = get_formatted_ptb_data()\n",
    "from ptb_xl_data_formatter import *\n",
    "os.environ[\"PTB_XL_FOLDER_PATH\"] = \"/home/jupyter/data/physionet.org/files/ptb-xl/1.0.1\"\n",
    "all_patient_data = get_formatted_ptb_xl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b223233-9187-45c8-9eba-380a2af6448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae82c67-5781-4bca-940d-3e70b636b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90043475-653d-4b3c-abdf-cbbfb98b8711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create individual df for each class\n",
    "mi_df = pd.DataFrame()\n",
    "norm_df = pd.DataFrame()\n",
    "non_mi_df = pd.DataFrame()\n",
    "\n",
    "for recording in all_patient_data.keys():\n",
    "    label = all_patient_data[recording][\"diagnostic_class\"][0]\n",
    "    signal = all_patient_data[recording][\"I\"]\n",
    "    \n",
    "    # Clean Signal\n",
    "    signal = clean_ecg_signal(signal, old_fs=500)\n",
    "    signal = pd.DataFrame(signal)\n",
    "    if label == \"mi\":\n",
    "        mi_df[recording] = signal\n",
    "    elif label == \"norm\":\n",
    "        norm_df[recording] = signal\n",
    "    elif label == \"non_mi\":\n",
    "        non_mi_df[recording] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c44118d-d371-4fd8-8530-db70995e34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_1</th>\n",
       "      <th>ecg_id_2</th>\n",
       "      <th>ecg_id_3</th>\n",
       "      <th>ecg_id_4</th>\n",
       "      <th>ecg_id_5</th>\n",
       "      <th>ecg_id_6</th>\n",
       "      <th>ecg_id_7</th>\n",
       "      <th>ecg_id_9</th>\n",
       "      <th>ecg_id_10</th>\n",
       "      <th>ecg_id_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21814</th>\n",
       "      <th>ecg_id_21818</th>\n",
       "      <th>ecg_id_21822</th>\n",
       "      <th>ecg_id_21823</th>\n",
       "      <th>ecg_id_21825</th>\n",
       "      <th>ecg_id_21830</th>\n",
       "      <th>ecg_id_21831</th>\n",
       "      <th>ecg_id_21834</th>\n",
       "      <th>ecg_id_21836</th>\n",
       "      <th>ecg_id_21837</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>-0.039000</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.028732</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>-0.021314</td>\n",
       "      <td>-0.039865</td>\n",
       "      <td>0.029101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023012</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.016769</td>\n",
       "      <td>-0.006891</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.007398</td>\n",
       "      <td>-0.006681</td>\n",
       "      <td>-0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012923</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>-0.040540</td>\n",
       "      <td>-0.003672</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.029169</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-0.040053</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023845</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>-0.008623</td>\n",
       "      <td>-0.004408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015592</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-0.004065</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.029958</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.030743</td>\n",
       "      <td>-0.040922</td>\n",
       "      <td>0.034173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.004136</td>\n",
       "      <td>-0.023896</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>-0.015739</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>-0.010028</td>\n",
       "      <td>-0.004711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017107</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>-0.043554</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.030994</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.032745</td>\n",
       "      <td>-0.042824</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024848</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>-0.024516</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>-0.003093</td>\n",
       "      <td>-0.010945</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>-0.044784</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.004724</td>\n",
       "      <td>-0.032476</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024894</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>-0.004322</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.010007</td>\n",
       "      <td>-0.004983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.005493</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>-0.007596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.004969</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.005355</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>-0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>-0.003660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.004574</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>-0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.004258</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>-0.005464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.003666</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>-0.004658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 8938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_1  ecg_id_2  ecg_id_3  ecg_id_4  ecg_id_5  ecg_id_6  ecg_id_7  \\\n",
       "0    -0.009347  0.003970 -0.039000 -0.003108 -0.000459 -0.028732 -0.004423   \n",
       "1    -0.012923  0.004130 -0.040540 -0.003672 -0.000078 -0.029169 -0.004455   \n",
       "2    -0.015592  0.004313 -0.042083 -0.004065  0.000122 -0.029958 -0.004510   \n",
       "3    -0.017107  0.004451 -0.043554 -0.004296  0.000013 -0.030994 -0.004599   \n",
       "4    -0.017702  0.004352 -0.044784 -0.004461 -0.000443 -0.031639 -0.004724   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4595  0.005499 -0.000025 -0.005809 -0.003973 -0.000129  0.003427 -0.000903   \n",
       "4596  0.004969 -0.000020 -0.005355 -0.003513 -0.000112  0.003118 -0.000827   \n",
       "4597  0.004487  0.000015 -0.004830 -0.002628 -0.000100  0.002773 -0.000746   \n",
       "4598  0.004102  0.000069 -0.004258 -0.001457 -0.000090  0.002404 -0.000664   \n",
       "4599  0.003807  0.000131 -0.003666 -0.000155 -0.000081  0.002027 -0.000581   \n",
       "\n",
       "      ecg_id_9  ecg_id_10  ecg_id_11  ...  ecg_id_21814  ecg_id_21818  \\\n",
       "0    -0.021314  -0.039865   0.029101  ...     -0.023012     -0.001422   \n",
       "1    -0.026685  -0.040053   0.031884  ...     -0.023845     -0.001576   \n",
       "2    -0.030743  -0.040922   0.034173  ...     -0.024496     -0.001693   \n",
       "3    -0.032745  -0.042824   0.035931  ...     -0.024848     -0.001744   \n",
       "4    -0.032476  -0.045653   0.037407  ...     -0.024894     -0.001723   \n",
       "...        ...        ...        ...  ...           ...           ...   \n",
       "4595  0.001467  -0.001330  -0.004544  ...     -0.000153     -0.003259   \n",
       "4596  0.001179  -0.001239  -0.004117  ...     -0.000156     -0.002987   \n",
       "4597  0.001030  -0.001149  -0.003660  ...     -0.000158     -0.002663   \n",
       "4598  0.001095  -0.001061  -0.003228  ...     -0.000160     -0.002303   \n",
       "4599  0.001340  -0.000972  -0.002839  ...     -0.000163     -0.001929   \n",
       "\n",
       "      ecg_id_21822  ecg_id_21823  ecg_id_21825  ecg_id_21830  ecg_id_21831  \\\n",
       "0        -0.003744     -0.021490     -0.016769     -0.006891     -0.002969   \n",
       "1        -0.003956     -0.022829     -0.012274     -0.011858     -0.003013   \n",
       "2        -0.004136     -0.023896     -0.008044     -0.015739     -0.003054   \n",
       "3        -0.004260     -0.024516     -0.004839     -0.017761     -0.003093   \n",
       "4        -0.004322     -0.024624     -0.004421     -0.017430     -0.003139   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.001467     -0.001109     -0.001520      0.000290     -0.005493   \n",
       "4596      0.001340     -0.001026     -0.001357      0.000260     -0.005039   \n",
       "4597      0.001202     -0.000937     -0.001185      0.000295     -0.004574   \n",
       "4598      0.001057     -0.000844     -0.001008      0.000377     -0.004103   \n",
       "4599      0.000908     -0.000748     -0.000831      0.000483     -0.003630   \n",
       "\n",
       "      ecg_id_21834  ecg_id_21836  ecg_id_21837  \n",
       "0        -0.007398     -0.006681     -0.004043  \n",
       "1        -0.009197     -0.008623     -0.004408  \n",
       "2        -0.010527     -0.010028     -0.004711  \n",
       "3        -0.010945     -0.010549     -0.004907  \n",
       "4        -0.010145     -0.010007     -0.004983  \n",
       "...            ...           ...           ...  \n",
       "4595      0.000944      0.004262     -0.007596  \n",
       "4596      0.000856      0.003903     -0.006966  \n",
       "4597      0.000773      0.003509     -0.006244  \n",
       "4598      0.000695      0.003093     -0.005464  \n",
       "4599      0.000619      0.002671     -0.004658  \n",
       "\n",
       "[4600 rows x 8938 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ee3ee7-7c18-4b0a-ba01-2b1a9c92264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_77</th>\n",
       "      <th>ecg_id_106</th>\n",
       "      <th>ecg_id_131</th>\n",
       "      <th>ecg_id_139</th>\n",
       "      <th>ecg_id_152</th>\n",
       "      <th>ecg_id_162</th>\n",
       "      <th>ecg_id_177</th>\n",
       "      <th>ecg_id_181</th>\n",
       "      <th>ecg_id_184</th>\n",
       "      <th>ecg_id_189</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21788</th>\n",
       "      <th>ecg_id_21793</th>\n",
       "      <th>ecg_id_21796</th>\n",
       "      <th>ecg_id_21799</th>\n",
       "      <th>ecg_id_21805</th>\n",
       "      <th>ecg_id_21811</th>\n",
       "      <th>ecg_id_21815</th>\n",
       "      <th>ecg_id_21826</th>\n",
       "      <th>ecg_id_21827</th>\n",
       "      <th>ecg_id_21828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038216</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.018618</td>\n",
       "      <td>-0.024321</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>-0.007663</td>\n",
       "      <td>-0.032769</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.353304</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.019221</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>-0.028041</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>-0.009266</td>\n",
       "      <td>-0.032548</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.021936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.360804</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.020913</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>-0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039715</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.019885</td>\n",
       "      <td>-0.030967</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>-0.032718</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.022117</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>-0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040454</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.020368</td>\n",
       "      <td>-0.032966</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.010664</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>0.396816</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>-0.022629</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>-0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040977</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>-0.034439</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.034861</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>0.438201</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>-0.022710</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>-0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>-0.008708</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018354</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.007124</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.006392</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.006327</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.001831</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>-0.002459</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 4145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_77  ecg_id_106  ecg_id_131  ecg_id_139  ecg_id_152  ecg_id_162  \\\n",
       "0     -0.038216   -0.000989   -0.018618   -0.024321   -0.004008    0.004239   \n",
       "1     -0.038924   -0.000582   -0.019282   -0.028041   -0.004006    0.004611   \n",
       "2     -0.039715   -0.000276   -0.019885   -0.030967   -0.003715    0.004879   \n",
       "3     -0.040454   -0.000139   -0.020368   -0.032966   -0.002968    0.004980   \n",
       "4     -0.040977   -0.000192   -0.020707   -0.034439   -0.001936    0.004937   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "4595  -0.000371   -0.003030   -0.001336   -0.012455    0.003633    0.000759   \n",
       "4596  -0.000364   -0.002777   -0.001236   -0.011647    0.003335    0.000700   \n",
       "4597  -0.000373   -0.002482   -0.001112   -0.010651    0.003025    0.000636   \n",
       "4598  -0.000401   -0.002162   -0.000973   -0.009366    0.002709    0.000570   \n",
       "4599  -0.000443   -0.001831   -0.000828   -0.007837    0.002391    0.000503   \n",
       "\n",
       "      ecg_id_177  ecg_id_181  ecg_id_184  ecg_id_189  ...  ecg_id_21788  \\\n",
       "0      -0.007663   -0.032769    0.008102    0.020674  ...     -0.003852   \n",
       "1      -0.009266   -0.032548    0.006741    0.021936  ...     -0.003325   \n",
       "2      -0.010420   -0.032718    0.005921    0.022862  ...     -0.003049   \n",
       "3      -0.010664   -0.033484    0.005843    0.023257  ...     -0.003045   \n",
       "4      -0.009600   -0.034861    0.006418    0.023114  ...     -0.003172   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "4595   -0.008535   -0.007130   -0.004652    0.002573  ...     -0.020067   \n",
       "4596   -0.007842   -0.006564   -0.004190    0.002382  ...     -0.018354   \n",
       "4597   -0.007124   -0.005976   -0.003465    0.002184  ...     -0.016345   \n",
       "4598   -0.006392   -0.005377   -0.002566    0.001982  ...     -0.014145   \n",
       "4599   -0.005655   -0.004774   -0.001587    0.001780  ...     -0.011864   \n",
       "\n",
       "      ecg_id_21793  ecg_id_21796  ecg_id_21799  ecg_id_21805  ecg_id_21811  \\\n",
       "0         0.353304      0.013632      0.012455      0.000497     -0.019221   \n",
       "1         0.360804      0.014458      0.013331      0.000873     -0.020913   \n",
       "2         0.373210      0.015139      0.014043      0.001158     -0.022117   \n",
       "3         0.396816      0.015568      0.014469      0.001291     -0.022629   \n",
       "4         0.438201      0.015712      0.014571      0.001255     -0.022710   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.009014     -0.000256      0.002257     -0.003724     -0.008708   \n",
       "4596      0.009014     -0.000223      0.002080     -0.003414     -0.007997   \n",
       "4597      0.008317     -0.000192      0.001892     -0.003097     -0.007192   \n",
       "4598      0.006642     -0.000162      0.001700     -0.002778     -0.006327   \n",
       "4599      0.004176     -0.000134      0.001505     -0.002459     -0.005438   \n",
       "\n",
       "      ecg_id_21815  ecg_id_21826  ecg_id_21827  ecg_id_21828  \n",
       "0         0.005553      0.011715      0.010180     -0.001342  \n",
       "1         0.006690      0.011091      0.010963     -0.001450  \n",
       "2         0.008079      0.010091      0.011743     -0.001540  \n",
       "3         0.009693      0.008625      0.012379     -0.001597  \n",
       "4         0.011035      0.007408      0.012609     -0.001618  \n",
       "...            ...           ...           ...           ...  \n",
       "4595      0.002847      0.001047      0.000090      0.001465  \n",
       "4596      0.002616      0.000958      0.000097      0.001339  \n",
       "4597      0.002389      0.000856      0.000102      0.001210  \n",
       "4598      0.002166      0.000748      0.000105      0.001079  \n",
       "4599      0.001945      0.000636      0.000109      0.000947  \n",
       "\n",
       "[4600 rows x 4145 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad8b9d2-36a9-42ef-a824-612b89d61211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_17</th>\n",
       "      <th>ecg_id_18</th>\n",
       "      <th>ecg_id_20</th>\n",
       "      <th>ecg_id_22</th>\n",
       "      <th>ecg_id_23</th>\n",
       "      <th>ecg_id_26</th>\n",
       "      <th>ecg_id_28</th>\n",
       "      <th>ecg_id_30</th>\n",
       "      <th>ecg_id_32</th>\n",
       "      <th>ecg_id_34</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21806</th>\n",
       "      <th>ecg_id_21812</th>\n",
       "      <th>ecg_id_21816</th>\n",
       "      <th>ecg_id_21817</th>\n",
       "      <th>ecg_id_21819</th>\n",
       "      <th>ecg_id_21821</th>\n",
       "      <th>ecg_id_21829</th>\n",
       "      <th>ecg_id_21832</th>\n",
       "      <th>ecg_id_21833</th>\n",
       "      <th>ecg_id_21835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020789</td>\n",
       "      <td>-0.044607</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.014863</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.007912</td>\n",
       "      <td>0.072998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>-0.016424</td>\n",
       "      <td>-0.010705</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.038642</td>\n",
       "      <td>-0.017364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.022534</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.023951</td>\n",
       "      <td>-0.040538</td>\n",
       "      <td>-0.006658</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.123542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>-0.017545</td>\n",
       "      <td>-0.012709</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.040612</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.038123</td>\n",
       "      <td>-0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024929</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.023457</td>\n",
       "      <td>-0.042989</td>\n",
       "      <td>-0.006916</td>\n",
       "      <td>-0.007233</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.008007</td>\n",
       "      <td>0.162820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>-0.040717</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>-0.039146</td>\n",
       "      <td>-0.008225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027371</td>\n",
       "      <td>-0.046922</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.023816</td>\n",
       "      <td>-0.043179</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.006705</td>\n",
       "      <td>-0.007965</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.178342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>-0.041912</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>-0.042718</td>\n",
       "      <td>-0.004455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027478</td>\n",
       "      <td>-0.048258</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.006149</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>-0.008052</td>\n",
       "      <td>-0.008969</td>\n",
       "      <td>0.156886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013407</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>-0.012525</td>\n",
       "      <td>-0.006498</td>\n",
       "      <td>-0.044389</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>-0.048779</td>\n",
       "      <td>-0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.002525</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>-0.021608</td>\n",
       "      <td>-0.004067</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030718</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.002484</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>-0.003760</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027790</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>-0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.002678</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-0.007574</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.018068</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-0.007187</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.016270</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.006690</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>-0.014475</td>\n",
       "      <td>-0.002522</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>-0.000605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 7815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_17  ecg_id_18  ecg_id_20  ecg_id_22  ecg_id_23  ecg_id_26  \\\n",
       "0     -0.020789  -0.044607  -0.001175  -0.025060  -0.037304  -0.005681   \n",
       "1     -0.022534  -0.045078  -0.001420  -0.023951  -0.040538  -0.006658   \n",
       "2     -0.024929  -0.045824  -0.001521  -0.023457  -0.042989  -0.006916   \n",
       "3     -0.027371  -0.046922  -0.001447  -0.023816  -0.043179  -0.006485   \n",
       "4     -0.027478  -0.048258  -0.001239  -0.024972  -0.039306  -0.006149   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4595  -0.002525  -0.008924   0.000351   0.001532  -0.008504   0.002741   \n",
       "4596  -0.002484  -0.008285   0.000323   0.001453  -0.007954   0.002487   \n",
       "4597  -0.002678  -0.007712   0.000286   0.001300  -0.007574   0.002239   \n",
       "4598  -0.003031  -0.007187   0.000244   0.001050  -0.007306   0.002020   \n",
       "4599  -0.003460  -0.006690   0.000200   0.000722  -0.007090   0.001832   \n",
       "\n",
       "      ecg_id_28  ecg_id_30  ecg_id_32  ecg_id_34  ...  ecg_id_21806  \\\n",
       "0     -0.014863  -0.005984  -0.007912   0.072998  ...     -0.004031   \n",
       "1     -0.010334  -0.006977  -0.007887   0.123542  ...     -0.007671   \n",
       "2     -0.007233  -0.007651  -0.008007   0.162820  ...     -0.010359   \n",
       "3     -0.006705  -0.007965  -0.008363   0.178342  ...     -0.012087   \n",
       "4     -0.009506  -0.008052  -0.008969   0.156886  ...     -0.013407   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "4595  -0.021608  -0.004067  -0.000269   0.010352  ...      0.030718   \n",
       "4596  -0.019854  -0.003760  -0.000252   0.010404  ...      0.027790   \n",
       "4597  -0.018068  -0.003398  -0.000239   0.009925  ...      0.024824   \n",
       "4598  -0.016270  -0.002979  -0.000228   0.008690  ...      0.022140   \n",
       "4599  -0.014475  -0.002522  -0.000219   0.006842  ...      0.019799   \n",
       "\n",
       "      ecg_id_21812  ecg_id_21816  ecg_id_21817  ecg_id_21819  ecg_id_21821  \\\n",
       "0         0.003311     -0.002510     -0.016424     -0.010705     -0.006108   \n",
       "1         0.002737     -0.001892     -0.017545     -0.012709     -0.006089   \n",
       "2         0.002675     -0.001150     -0.018455     -0.014036     -0.006124   \n",
       "3         0.003402     -0.000393     -0.018975     -0.014084     -0.006251   \n",
       "4         0.004868     -0.000180     -0.019009     -0.012525     -0.006498   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.000541      0.000917     -0.000884     -0.005866     -0.005420   \n",
       "4596      0.000493      0.000846     -0.000823     -0.005401     -0.004976   \n",
       "4597      0.000436      0.000770     -0.000770     -0.004908     -0.004456   \n",
       "4598      0.000374      0.000692     -0.000722     -0.004397     -0.003888   \n",
       "4599      0.000309      0.000611     -0.000676     -0.003881     -0.003299   \n",
       "\n",
       "      ecg_id_21829  ecg_id_21832  ecg_id_21833  ecg_id_21835  \n",
       "0        -0.041105     -0.005660     -0.038642     -0.017364  \n",
       "1        -0.040612     -0.006637     -0.038123     -0.012750  \n",
       "2        -0.040717     -0.007312     -0.039146     -0.008225  \n",
       "3        -0.041912     -0.007466     -0.042718     -0.004455  \n",
       "4        -0.044389     -0.007023     -0.048779     -0.003396  \n",
       "...            ...           ...           ...           ...  \n",
       "4595     -0.007793      0.005081     -0.008164     -0.001286  \n",
       "4596     -0.007036      0.004661     -0.007511     -0.001148  \n",
       "4597     -0.005838      0.004222     -0.006819     -0.000982  \n",
       "4598     -0.004348      0.003774     -0.006108     -0.000797  \n",
       "4599     -0.002726      0.003325     -0.005394     -0.000605  \n",
       "\n",
       "[4600 rows x 7815 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c17730-f526-4c72-80a3-17c3fa0d656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete any column in which any reading is NaN\n",
    "norm_df = norm_df.dropna(axis=1)\n",
    "mi_df = mi_df.dropna(axis=1)\n",
    "non_mi_df = non_mi_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98374105-1d6a-4a47-9db9-e8b07fcee4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_1</th>\n",
       "      <th>ecg_id_2</th>\n",
       "      <th>ecg_id_3</th>\n",
       "      <th>ecg_id_4</th>\n",
       "      <th>ecg_id_5</th>\n",
       "      <th>ecg_id_6</th>\n",
       "      <th>ecg_id_7</th>\n",
       "      <th>ecg_id_9</th>\n",
       "      <th>ecg_id_10</th>\n",
       "      <th>ecg_id_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21814</th>\n",
       "      <th>ecg_id_21818</th>\n",
       "      <th>ecg_id_21822</th>\n",
       "      <th>ecg_id_21823</th>\n",
       "      <th>ecg_id_21825</th>\n",
       "      <th>ecg_id_21830</th>\n",
       "      <th>ecg_id_21831</th>\n",
       "      <th>ecg_id_21834</th>\n",
       "      <th>ecg_id_21836</th>\n",
       "      <th>ecg_id_21837</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>-0.039000</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.028732</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>-0.021314</td>\n",
       "      <td>-0.039865</td>\n",
       "      <td>0.029101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023012</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.003744</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.016769</td>\n",
       "      <td>-0.006891</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.007398</td>\n",
       "      <td>-0.006681</td>\n",
       "      <td>-0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012923</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>-0.040540</td>\n",
       "      <td>-0.003672</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.029169</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-0.040053</td>\n",
       "      <td>0.031884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023845</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>-0.008623</td>\n",
       "      <td>-0.004408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015592</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-0.004065</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.029958</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.030743</td>\n",
       "      <td>-0.040922</td>\n",
       "      <td>0.034173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024496</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.004136</td>\n",
       "      <td>-0.023896</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>-0.015739</td>\n",
       "      <td>-0.003054</td>\n",
       "      <td>-0.010527</td>\n",
       "      <td>-0.010028</td>\n",
       "      <td>-0.004711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017107</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>-0.043554</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.030994</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.032745</td>\n",
       "      <td>-0.042824</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024848</td>\n",
       "      <td>-0.001744</td>\n",
       "      <td>-0.004260</td>\n",
       "      <td>-0.024516</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>-0.003093</td>\n",
       "      <td>-0.010945</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>-0.044784</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.031639</td>\n",
       "      <td>-0.004724</td>\n",
       "      <td>-0.032476</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024894</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>-0.004322</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.010007</td>\n",
       "      <td>-0.004983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>-0.003973</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.004544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.003259</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.005493</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>-0.007596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.004969</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.005355</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>-0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.004830</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>-0.003660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.004574</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>-0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.004258</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>-0.005464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.003666</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>-0.004658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 8938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_1  ecg_id_2  ecg_id_3  ecg_id_4  ecg_id_5  ecg_id_6  ecg_id_7  \\\n",
       "0    -0.009347  0.003970 -0.039000 -0.003108 -0.000459 -0.028732 -0.004423   \n",
       "1    -0.012923  0.004130 -0.040540 -0.003672 -0.000078 -0.029169 -0.004455   \n",
       "2    -0.015592  0.004313 -0.042083 -0.004065  0.000122 -0.029958 -0.004510   \n",
       "3    -0.017107  0.004451 -0.043554 -0.004296  0.000013 -0.030994 -0.004599   \n",
       "4    -0.017702  0.004352 -0.044784 -0.004461 -0.000443 -0.031639 -0.004724   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4595  0.005499 -0.000025 -0.005809 -0.003973 -0.000129  0.003427 -0.000903   \n",
       "4596  0.004969 -0.000020 -0.005355 -0.003513 -0.000112  0.003118 -0.000827   \n",
       "4597  0.004487  0.000015 -0.004830 -0.002628 -0.000100  0.002773 -0.000746   \n",
       "4598  0.004102  0.000069 -0.004258 -0.001457 -0.000090  0.002404 -0.000664   \n",
       "4599  0.003807  0.000131 -0.003666 -0.000155 -0.000081  0.002027 -0.000581   \n",
       "\n",
       "      ecg_id_9  ecg_id_10  ecg_id_11  ...  ecg_id_21814  ecg_id_21818  \\\n",
       "0    -0.021314  -0.039865   0.029101  ...     -0.023012     -0.001422   \n",
       "1    -0.026685  -0.040053   0.031884  ...     -0.023845     -0.001576   \n",
       "2    -0.030743  -0.040922   0.034173  ...     -0.024496     -0.001693   \n",
       "3    -0.032745  -0.042824   0.035931  ...     -0.024848     -0.001744   \n",
       "4    -0.032476  -0.045653   0.037407  ...     -0.024894     -0.001723   \n",
       "...        ...        ...        ...  ...           ...           ...   \n",
       "4595  0.001467  -0.001330  -0.004544  ...     -0.000153     -0.003259   \n",
       "4596  0.001179  -0.001239  -0.004117  ...     -0.000156     -0.002987   \n",
       "4597  0.001030  -0.001149  -0.003660  ...     -0.000158     -0.002663   \n",
       "4598  0.001095  -0.001061  -0.003228  ...     -0.000160     -0.002303   \n",
       "4599  0.001340  -0.000972  -0.002839  ...     -0.000163     -0.001929   \n",
       "\n",
       "      ecg_id_21822  ecg_id_21823  ecg_id_21825  ecg_id_21830  ecg_id_21831  \\\n",
       "0        -0.003744     -0.021490     -0.016769     -0.006891     -0.002969   \n",
       "1        -0.003956     -0.022829     -0.012274     -0.011858     -0.003013   \n",
       "2        -0.004136     -0.023896     -0.008044     -0.015739     -0.003054   \n",
       "3        -0.004260     -0.024516     -0.004839     -0.017761     -0.003093   \n",
       "4        -0.004322     -0.024624     -0.004421     -0.017430     -0.003139   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.001467     -0.001109     -0.001520      0.000290     -0.005493   \n",
       "4596      0.001340     -0.001026     -0.001357      0.000260     -0.005039   \n",
       "4597      0.001202     -0.000937     -0.001185      0.000295     -0.004574   \n",
       "4598      0.001057     -0.000844     -0.001008      0.000377     -0.004103   \n",
       "4599      0.000908     -0.000748     -0.000831      0.000483     -0.003630   \n",
       "\n",
       "      ecg_id_21834  ecg_id_21836  ecg_id_21837  \n",
       "0        -0.007398     -0.006681     -0.004043  \n",
       "1        -0.009197     -0.008623     -0.004408  \n",
       "2        -0.010527     -0.010028     -0.004711  \n",
       "3        -0.010945     -0.010549     -0.004907  \n",
       "4        -0.010145     -0.010007     -0.004983  \n",
       "...            ...           ...           ...  \n",
       "4595      0.000944      0.004262     -0.007596  \n",
       "4596      0.000856      0.003903     -0.006966  \n",
       "4597      0.000773      0.003509     -0.006244  \n",
       "4598      0.000695      0.003093     -0.005464  \n",
       "4599      0.000619      0.002671     -0.004658  \n",
       "\n",
       "[4600 rows x 8938 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705c4453-7e80-4268-93fe-77b8558e6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_77</th>\n",
       "      <th>ecg_id_106</th>\n",
       "      <th>ecg_id_131</th>\n",
       "      <th>ecg_id_139</th>\n",
       "      <th>ecg_id_152</th>\n",
       "      <th>ecg_id_162</th>\n",
       "      <th>ecg_id_177</th>\n",
       "      <th>ecg_id_181</th>\n",
       "      <th>ecg_id_184</th>\n",
       "      <th>ecg_id_189</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21788</th>\n",
       "      <th>ecg_id_21793</th>\n",
       "      <th>ecg_id_21796</th>\n",
       "      <th>ecg_id_21799</th>\n",
       "      <th>ecg_id_21805</th>\n",
       "      <th>ecg_id_21811</th>\n",
       "      <th>ecg_id_21815</th>\n",
       "      <th>ecg_id_21826</th>\n",
       "      <th>ecg_id_21827</th>\n",
       "      <th>ecg_id_21828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038216</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.018618</td>\n",
       "      <td>-0.024321</td>\n",
       "      <td>-0.004008</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>-0.007663</td>\n",
       "      <td>-0.032769</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.353304</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.019221</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>-0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038924</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>-0.028041</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>-0.009266</td>\n",
       "      <td>-0.032548</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.021936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.360804</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.020913</td>\n",
       "      <td>0.006690</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>-0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039715</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.019885</td>\n",
       "      <td>-0.030967</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>-0.032718</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.373210</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.014043</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>-0.022117</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>-0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040454</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.020368</td>\n",
       "      <td>-0.032966</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.010664</td>\n",
       "      <td>-0.033484</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>0.396816</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>-0.022629</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>-0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.040977</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>-0.020707</td>\n",
       "      <td>-0.034439</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.034861</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>0.438201</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>-0.022710</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>-0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>-0.007130</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>-0.003724</td>\n",
       "      <td>-0.008708</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018354</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.007124</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>-0.003465</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.002162</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.006392</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.006327</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.001831</td>\n",
       "      <td>-0.000828</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.001587</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>-0.002459</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 4145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_77  ecg_id_106  ecg_id_131  ecg_id_139  ecg_id_152  ecg_id_162  \\\n",
       "0     -0.038216   -0.000989   -0.018618   -0.024321   -0.004008    0.004239   \n",
       "1     -0.038924   -0.000582   -0.019282   -0.028041   -0.004006    0.004611   \n",
       "2     -0.039715   -0.000276   -0.019885   -0.030967   -0.003715    0.004879   \n",
       "3     -0.040454   -0.000139   -0.020368   -0.032966   -0.002968    0.004980   \n",
       "4     -0.040977   -0.000192   -0.020707   -0.034439   -0.001936    0.004937   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "4595  -0.000371   -0.003030   -0.001336   -0.012455    0.003633    0.000759   \n",
       "4596  -0.000364   -0.002777   -0.001236   -0.011647    0.003335    0.000700   \n",
       "4597  -0.000373   -0.002482   -0.001112   -0.010651    0.003025    0.000636   \n",
       "4598  -0.000401   -0.002162   -0.000973   -0.009366    0.002709    0.000570   \n",
       "4599  -0.000443   -0.001831   -0.000828   -0.007837    0.002391    0.000503   \n",
       "\n",
       "      ecg_id_177  ecg_id_181  ecg_id_184  ecg_id_189  ...  ecg_id_21788  \\\n",
       "0      -0.007663   -0.032769    0.008102    0.020674  ...     -0.003852   \n",
       "1      -0.009266   -0.032548    0.006741    0.021936  ...     -0.003325   \n",
       "2      -0.010420   -0.032718    0.005921    0.022862  ...     -0.003049   \n",
       "3      -0.010664   -0.033484    0.005843    0.023257  ...     -0.003045   \n",
       "4      -0.009600   -0.034861    0.006418    0.023114  ...     -0.003172   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "4595   -0.008535   -0.007130   -0.004652    0.002573  ...     -0.020067   \n",
       "4596   -0.007842   -0.006564   -0.004190    0.002382  ...     -0.018354   \n",
       "4597   -0.007124   -0.005976   -0.003465    0.002184  ...     -0.016345   \n",
       "4598   -0.006392   -0.005377   -0.002566    0.001982  ...     -0.014145   \n",
       "4599   -0.005655   -0.004774   -0.001587    0.001780  ...     -0.011864   \n",
       "\n",
       "      ecg_id_21793  ecg_id_21796  ecg_id_21799  ecg_id_21805  ecg_id_21811  \\\n",
       "0         0.353304      0.013632      0.012455      0.000497     -0.019221   \n",
       "1         0.360804      0.014458      0.013331      0.000873     -0.020913   \n",
       "2         0.373210      0.015139      0.014043      0.001158     -0.022117   \n",
       "3         0.396816      0.015568      0.014469      0.001291     -0.022629   \n",
       "4         0.438201      0.015712      0.014571      0.001255     -0.022710   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.009014     -0.000256      0.002257     -0.003724     -0.008708   \n",
       "4596      0.009014     -0.000223      0.002080     -0.003414     -0.007997   \n",
       "4597      0.008317     -0.000192      0.001892     -0.003097     -0.007192   \n",
       "4598      0.006642     -0.000162      0.001700     -0.002778     -0.006327   \n",
       "4599      0.004176     -0.000134      0.001505     -0.002459     -0.005438   \n",
       "\n",
       "      ecg_id_21815  ecg_id_21826  ecg_id_21827  ecg_id_21828  \n",
       "0         0.005553      0.011715      0.010180     -0.001342  \n",
       "1         0.006690      0.011091      0.010963     -0.001450  \n",
       "2         0.008079      0.010091      0.011743     -0.001540  \n",
       "3         0.009693      0.008625      0.012379     -0.001597  \n",
       "4         0.011035      0.007408      0.012609     -0.001618  \n",
       "...            ...           ...           ...           ...  \n",
       "4595      0.002847      0.001047      0.000090      0.001465  \n",
       "4596      0.002616      0.000958      0.000097      0.001339  \n",
       "4597      0.002389      0.000856      0.000102      0.001210  \n",
       "4598      0.002166      0.000748      0.000105      0.001079  \n",
       "4599      0.001945      0.000636      0.000109      0.000947  \n",
       "\n",
       "[4600 rows x 4145 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35738de9-ac1c-4976-8839-66b8289925d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_17</th>\n",
       "      <th>ecg_id_18</th>\n",
       "      <th>ecg_id_20</th>\n",
       "      <th>ecg_id_22</th>\n",
       "      <th>ecg_id_23</th>\n",
       "      <th>ecg_id_26</th>\n",
       "      <th>ecg_id_28</th>\n",
       "      <th>ecg_id_30</th>\n",
       "      <th>ecg_id_32</th>\n",
       "      <th>ecg_id_34</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21806</th>\n",
       "      <th>ecg_id_21812</th>\n",
       "      <th>ecg_id_21816</th>\n",
       "      <th>ecg_id_21817</th>\n",
       "      <th>ecg_id_21819</th>\n",
       "      <th>ecg_id_21821</th>\n",
       "      <th>ecg_id_21829</th>\n",
       "      <th>ecg_id_21832</th>\n",
       "      <th>ecg_id_21833</th>\n",
       "      <th>ecg_id_21835</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020789</td>\n",
       "      <td>-0.044607</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.025060</td>\n",
       "      <td>-0.037304</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.014863</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.007912</td>\n",
       "      <td>0.072998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004031</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>-0.016424</td>\n",
       "      <td>-0.010705</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.038642</td>\n",
       "      <td>-0.017364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.022534</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>-0.001420</td>\n",
       "      <td>-0.023951</td>\n",
       "      <td>-0.040538</td>\n",
       "      <td>-0.006658</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.123542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007671</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>-0.017545</td>\n",
       "      <td>-0.012709</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.040612</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.038123</td>\n",
       "      <td>-0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024929</td>\n",
       "      <td>-0.045824</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.023457</td>\n",
       "      <td>-0.042989</td>\n",
       "      <td>-0.006916</td>\n",
       "      <td>-0.007233</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.008007</td>\n",
       "      <td>0.162820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010359</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>-0.040717</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>-0.039146</td>\n",
       "      <td>-0.008225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027371</td>\n",
       "      <td>-0.046922</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.023816</td>\n",
       "      <td>-0.043179</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.006705</td>\n",
       "      <td>-0.007965</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.178342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.018975</td>\n",
       "      <td>-0.014084</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>-0.041912</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>-0.042718</td>\n",
       "      <td>-0.004455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027478</td>\n",
       "      <td>-0.048258</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>-0.024972</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>-0.006149</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>-0.008052</td>\n",
       "      <td>-0.008969</td>\n",
       "      <td>0.156886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013407</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>-0.012525</td>\n",
       "      <td>-0.006498</td>\n",
       "      <td>-0.044389</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>-0.048779</td>\n",
       "      <td>-0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4595</th>\n",
       "      <td>-0.002525</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>-0.021608</td>\n",
       "      <td>-0.004067</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030718</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.008164</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>-0.002484</td>\n",
       "      <td>-0.008285</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>-0.003760</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027790</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.007036</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>-0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.002678</td>\n",
       "      <td>-0.007712</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-0.007574</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>-0.018068</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-0.007187</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.016270</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>-0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>-0.003460</td>\n",
       "      <td>-0.006690</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>-0.014475</td>\n",
       "      <td>-0.002522</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.002726</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>-0.005394</td>\n",
       "      <td>-0.000605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4600 rows × 7815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_17  ecg_id_18  ecg_id_20  ecg_id_22  ecg_id_23  ecg_id_26  \\\n",
       "0     -0.020789  -0.044607  -0.001175  -0.025060  -0.037304  -0.005681   \n",
       "1     -0.022534  -0.045078  -0.001420  -0.023951  -0.040538  -0.006658   \n",
       "2     -0.024929  -0.045824  -0.001521  -0.023457  -0.042989  -0.006916   \n",
       "3     -0.027371  -0.046922  -0.001447  -0.023816  -0.043179  -0.006485   \n",
       "4     -0.027478  -0.048258  -0.001239  -0.024972  -0.039306  -0.006149   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4595  -0.002525  -0.008924   0.000351   0.001532  -0.008504   0.002741   \n",
       "4596  -0.002484  -0.008285   0.000323   0.001453  -0.007954   0.002487   \n",
       "4597  -0.002678  -0.007712   0.000286   0.001300  -0.007574   0.002239   \n",
       "4598  -0.003031  -0.007187   0.000244   0.001050  -0.007306   0.002020   \n",
       "4599  -0.003460  -0.006690   0.000200   0.000722  -0.007090   0.001832   \n",
       "\n",
       "      ecg_id_28  ecg_id_30  ecg_id_32  ecg_id_34  ...  ecg_id_21806  \\\n",
       "0     -0.014863  -0.005984  -0.007912   0.072998  ...     -0.004031   \n",
       "1     -0.010334  -0.006977  -0.007887   0.123542  ...     -0.007671   \n",
       "2     -0.007233  -0.007651  -0.008007   0.162820  ...     -0.010359   \n",
       "3     -0.006705  -0.007965  -0.008363   0.178342  ...     -0.012087   \n",
       "4     -0.009506  -0.008052  -0.008969   0.156886  ...     -0.013407   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "4595  -0.021608  -0.004067  -0.000269   0.010352  ...      0.030718   \n",
       "4596  -0.019854  -0.003760  -0.000252   0.010404  ...      0.027790   \n",
       "4597  -0.018068  -0.003398  -0.000239   0.009925  ...      0.024824   \n",
       "4598  -0.016270  -0.002979  -0.000228   0.008690  ...      0.022140   \n",
       "4599  -0.014475  -0.002522  -0.000219   0.006842  ...      0.019799   \n",
       "\n",
       "      ecg_id_21812  ecg_id_21816  ecg_id_21817  ecg_id_21819  ecg_id_21821  \\\n",
       "0         0.003311     -0.002510     -0.016424     -0.010705     -0.006108   \n",
       "1         0.002737     -0.001892     -0.017545     -0.012709     -0.006089   \n",
       "2         0.002675     -0.001150     -0.018455     -0.014036     -0.006124   \n",
       "3         0.003402     -0.000393     -0.018975     -0.014084     -0.006251   \n",
       "4         0.004868     -0.000180     -0.019009     -0.012525     -0.006498   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4595      0.000541      0.000917     -0.000884     -0.005866     -0.005420   \n",
       "4596      0.000493      0.000846     -0.000823     -0.005401     -0.004976   \n",
       "4597      0.000436      0.000770     -0.000770     -0.004908     -0.004456   \n",
       "4598      0.000374      0.000692     -0.000722     -0.004397     -0.003888   \n",
       "4599      0.000309      0.000611     -0.000676     -0.003881     -0.003299   \n",
       "\n",
       "      ecg_id_21829  ecg_id_21832  ecg_id_21833  ecg_id_21835  \n",
       "0        -0.041105     -0.005660     -0.038642     -0.017364  \n",
       "1        -0.040612     -0.006637     -0.038123     -0.012750  \n",
       "2        -0.040717     -0.007312     -0.039146     -0.008225  \n",
       "3        -0.041912     -0.007466     -0.042718     -0.004455  \n",
       "4        -0.044389     -0.007023     -0.048779     -0.003396  \n",
       "...            ...           ...           ...           ...  \n",
       "4595     -0.007793      0.005081     -0.008164     -0.001286  \n",
       "4596     -0.007036      0.004661     -0.007511     -0.001148  \n",
       "4597     -0.005838      0.004222     -0.006819     -0.000982  \n",
       "4598     -0.004348      0.003774     -0.006108     -0.000797  \n",
       "4599     -0.002726      0.003325     -0.005394     -0.000605  \n",
       "\n",
       "[4600 rows x 7815 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "285d5892-07e8-4a68-8f1f-a4bdf2e4de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the order of the ecg recordings\n",
    "import random\n",
    "norm_cols = norm_df.columns.to_list()\n",
    "random.shuffle(norm_cols)\n",
    "mi_cols = mi_df.columns.to_list()\n",
    "random.shuffle(mi_cols)\n",
    "non_mi_cols = non_mi_df.columns.to_list()\n",
    "random.shuffle(non_mi_cols)\n",
    "norm_df = norm_df[norm_cols]\n",
    "mi_df = mi_df[mi_cols]\n",
    "non_mi_df = non_mi_df[non_mi_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d9314d-963b-4b6b-bf79-a8437bd20447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of norm cases: \n",
      "8938\n",
      "Number of MI cases: \n",
      "4145\n",
      "Number of non_MI cases: \n",
      "7815\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of norm cases: \")\n",
    "print(len(norm_df.columns))\n",
    "print(\"Number of MI cases: \")\n",
    "print(len(mi_df.columns))\n",
    "print(\"Number of non_MI cases: \")\n",
    "print(len(non_mi_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4d68c85-1ab6-4e32-bd91-ed062cee8333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32552, 512, 1)\n",
      "(69280, 512, 1)\n",
      "(61288, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "beat_len = 512\n",
    "\n",
    "mi_beats = []\n",
    "for ecg in mi_df.columns:\n",
    "    _mi_beats = []\n",
    "    sig = mi_df[ecg].to_numpy()\n",
    "    peaks = apply_pan_tompkins(sig, n_beats=8, standardize=True)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak]\n",
    "        _mi_beats.append(p)\n",
    "        \n",
    "    _mi_beats = np.array(_mi_beats)\n",
    "    \n",
    "    if np.shape(_mi_beats)[0] == 8:\n",
    "        # Shuffle sequence of beats\n",
    "        df = pd.DataFrame(np.reshape(_mi_beats, [8,beat_len]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _mi_beats = df.to_numpy()\n",
    "        _mi_beats = np.reshape(_mi_beats, [8,beat_len])\n",
    "        mi_beats.append(_mi_beats)\n",
    "\n",
    "norm_beats = []\n",
    "for ecg in norm_df.columns:\n",
    "    _norm_beats = []\n",
    "    sig = norm_df[ecg].to_numpy()\n",
    "    peaks = apply_pan_tompkins(sig, n_beats=8, standardize=True)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak]\n",
    "        _norm_beats.append(p)\n",
    "    \n",
    "    _norm_beats = np.array(_norm_beats)\n",
    "    \n",
    "    if np.shape(_norm_beats)[0] == 8:\n",
    "        # Shuffle sequence of beats\n",
    "        df = pd.DataFrame(np.reshape(_norm_beats, [8,beat_len]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _norm_beats = df.to_numpy()\n",
    "        _norm_beats = np.reshape(_norm_beats, [8,beat_len,1])\n",
    "        norm_beats.append(_norm_beats)\n",
    "        \n",
    "non_mi_beats = []\n",
    "for ecg in non_mi_df.columns:\n",
    "    _non_mi_beats = []\n",
    "    sig = non_mi_df[ecg].to_numpy()\n",
    "    peaks = apply_pan_tompkins(sig, n_beats=8, standardize=True)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak]\n",
    "        _non_mi_beats.append(p)\n",
    "   \n",
    "    _non_mi_beats = np.array(_non_mi_beats)\n",
    "    \n",
    "    if np.shape(_non_mi_beats)[0] == 8:\n",
    "        # Shuffle sequence of beats\n",
    "        df = pd.DataFrame(np.reshape(_non_mi_beats, [8,beat_len]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _non_mi_beats = df.to_numpy()\n",
    "        _non_mi_beats = np.reshape(_non_mi_beats, [8,beat_len,1])\n",
    "        non_mi_beats.append(_non_mi_beats)\n",
    "\n",
    "mi_beats = np.reshape(mi_beats, [-1,512,1])\n",
    "norm_beats = np.reshape(norm_beats, [-1,512,1])\n",
    "non_mi_beats = np.reshape(non_mi_beats, [-1,512,1])\n",
    "\n",
    "print(np.shape(mi_beats))\n",
    "print(np.shape(norm_beats))\n",
    "print(np.shape(non_mi_beats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12bb7220-6b61-4b0a-b772-1b90532a7e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78123, 512, 1)\n",
      "(78123, 3)\n",
      "(19533, 512, 1)\n",
      "(19533, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for model\n",
    "\n",
    "# Separate into train and test set with balanced class labels\n",
    "model_4_data_train = np.concatenate((mi_beats[0:int(0.8*len(mi_beats))], non_mi_beats[0:int(0.8*len(mi_beats))], norm_beats[0:int(0.8*len(mi_beats))]))\n",
    "model_4_data_test = np.concatenate((mi_beats[int(0.8*len(mi_beats)):], non_mi_beats[int(0.8*len(mi_beats)):len(mi_beats)], norm_beats[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Class labels: MI - [1,0,0], non-MI - [0,1,0], norm - [0,0,1]\n",
    "mi_label_model_4 = np.zeros((32552,3))\n",
    "non_mi_label_model_4 = np.zeros((32552,3))\n",
    "norm_label_model_4 = np.zeros((32552,3))\n",
    "\n",
    "for i in range(len(mi_label_model_4)):\n",
    "    mi_label_model_4[i] = [1,0,0]\n",
    "    non_mi_label_model_4[i] = [0,1,0]\n",
    "    norm_label_model_4[i] = [0,0,1]\n",
    "\n",
    "model_4_labels_train = np.concatenate((mi_label_model_4[0:int(0.8*len(mi_beats))], non_mi_label_model_4[0:int(0.8*len(mi_beats))], norm_label_model_4[0:int(0.8*len(mi_beats))]))\n",
    "model_4_labels_test = np.concatenate((mi_label_model_4[int(0.8*len(mi_beats)):], non_mi_label_model_4[int(0.8*len(mi_beats)):len(mi_beats)], norm_label_model_4[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_4_data_train, model_4_labels_train = shuffle(model_4_data_train, model_4_labels_train)\n",
    "model_4_data_test, model_4_labels_test = shuffle(model_4_data_test, model_4_labels_test)\n",
    "\n",
    "print(np.shape(model_4_data_train))\n",
    "print(np.shape(model_4_labels_train))\n",
    "\n",
    "print(np.shape(model_4_data_test))\n",
    "print(np.shape(model_4_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0c29635-d2c6-4d04-9e77-aeca282df74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_labels_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704561c4-be91-4b15-b9c3-89c1ca17b65c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4138068a-c464-4c42-a712-4955f015e044",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_lstm_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8, 512, 1)]       0         \n",
      "                                                                 \n",
      " time_distributed_113 (TimeD  (None, 8, 512, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_114 (TimeD  (None, 8, 512, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_115 (TimeD  (None, 8, 512, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_116 (TimeD  (None, 8, 512, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_117 (TimeD  (None, 8, 256, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_118 (TimeD  (None, 8, 256, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_119 (TimeD  (None, 8, 256, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_120 (TimeD  (None, 8, 256, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_121 (TimeD  (None, 8, 256, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_122 (TimeD  (None, 8, 256, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_123 (TimeD  (None, 8, 128, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_124 (TimeD  (None, 8, 128, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_125 (TimeD  (None, 8, 128, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_126 (TimeD  (None, 8, 128, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_127 (TimeD  (None, 8, 128, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_128 (TimeD  (None, 8, 128, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_129 (TimeD  (None, 8, 64, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_130 (TimeD  (None, 8, 64, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_131 (TimeD  (None, 8, 64, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_132 (TimeD  (None, 8, 64, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_133 (TimeD  (None, 8, 64, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_134 (TimeD  (None, 8, 64, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_135 (TimeD  (None, 8, 32, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_136 (TimeD  (None, 8, 32, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_137 (TimeD  (None, 8, 1024)          0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_138 (TimeD  (None, 8, 32)            32800     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_139 (TimeD  (None, 8, 32)            128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_140 (TimeD  (None, 8, 32)            0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,865\n",
      "Trainable params: 64,193\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "seq_length = 8\n",
    "beat_length = beat_len\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(seq_length, beat_length, num_feats))\n",
    "\n",
    "## Layers 1-6 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(input)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 7-12 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 13-19 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 19-24 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layer 25 - time-distributed flatten\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "## Layer 26 - time-distributed dense\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu'))(x)\n",
    "\n",
    "## Layer 27 - time-distributed batch norm\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "\n",
    "## Layer 28 - time-distributed dropout\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layer 29 - LSTM\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model_1 = tf.keras.Model(input, output, name=\"cnn_lstm_model_1\")\n",
    "cnn_lstm_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26f158bb-7ac1-4126-b1ef-44948abaec86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_lstm_model_1.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98b7da94-49f9-4dfa-9e57-a9d1ddf676db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 85s 383ms/step - loss: 0.9598 - binary_accuracy: 0.5000 - val_loss: 0.6973 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9e37f40110>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "cnn_lstm_model_1.fit(x=model_1_data_train, y=model_1_labels_train, validation_data=[model_1_data_test, model_1_labels_test], batch_size=32, epochs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb511e0-8980-486c-97a6-0cac284d775e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29c28ed5-6dbd-41f3-b385-37e1c0fe03f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_lstm_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8, 345, 1)]       0         \n",
      "                                                                 \n",
      " time_distributed_84 (TimeDi  (None, 8, 345, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_85 (TimeDi  (None, 8, 345, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_86 (TimeDi  (None, 8, 345, 32)       3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_87 (TimeDi  (None, 8, 345, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_88 (TimeDi  (None, 8, 172, 32)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_89 (TimeDi  (None, 8, 172, 32)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_90 (TimeDi  (None, 8, 172, 32)       3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_91 (TimeDi  (None, 8, 172, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_92 (TimeDi  (None, 8, 172, 32)       3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_93 (TimeDi  (None, 8, 172, 32)       128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_94 (TimeDi  (None, 8, 86, 32)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_95 (TimeDi  (None, 8, 86, 32)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_96 (TimeDi  (None, 8, 86, 32)        3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_97 (TimeDi  (None, 8, 86, 32)        128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_98 (TimeDi  (None, 8, 86, 32)        3104      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_99 (TimeDi  (None, 8, 86, 32)        128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_100 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_101 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_102 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_103 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_104 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_105 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_106 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_107 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_108 (TimeD  (None, 8, 672)           0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_109 (TimeD  (None, 8, 32)            21536     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_110 (TimeD  (None, 8, 32)            128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_111 (TimeD  (None, 8, 32)            0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,601\n",
      "Trainable params: 52,929\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "beat_length = 345\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(seq_length, beat_length, num_feats))\n",
    "\n",
    "## Layers 1-6 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(input)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 7-12 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 13-19 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 19-24 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layer 25 - time-distributed flatten\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "## Layer 26 - time-distributed dense\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu'))(x)\n",
    "\n",
    "## Layer 27 - time-distributed batch norm\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "\n",
    "## Layer 28 - time-distributed dropout\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layer 29 - LSTM\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model_2 = tf.keras.Model(input, output, name=\"cnn_lstm_model_2\")\n",
    "cnn_lstm_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dbbe9b1-ea26-43f8-869e-8394da56d84f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_lstm_model_2.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83c5585f-c249-4aae-8618-3e3c0488c6a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "184/184 [==============================] - 58s 273ms/step - loss: 0.5854 - binary_accuracy: 0.5000 - val_loss: 0.7433 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "184/184 [==============================] - 48s 262ms/step - loss: 0.4632 - binary_accuracy: 0.5000 - val_loss: 0.6859 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb73d495890>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm_model_2.fit(x=model_2_data_train, y=model_2_labels_train, validation_data=[model_2_data_test, model_2_labels_test], batch_size=32, epochs=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ce2997c-d311-4536-aa25-3cea50d78991",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_lstm_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8, 345, 1)]       0         \n",
      "                                                                 \n",
      " time_distributed_140 (TimeD  (None, 8, 345, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_141 (TimeD  (None, 8, 345, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_142 (TimeD  (None, 8, 345, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_143 (TimeD  (None, 8, 345, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_144 (TimeD  (None, 8, 172, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_145 (TimeD  (None, 8, 172, 32)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_146 (TimeD  (None, 8, 172, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_147 (TimeD  (None, 8, 172, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_148 (TimeD  (None, 8, 172, 32)       3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_149 (TimeD  (None, 8, 172, 32)       128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_150 (TimeD  (None, 8, 86, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_151 (TimeD  (None, 8, 86, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_152 (TimeD  (None, 8, 86, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_153 (TimeD  (None, 8, 86, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_154 (TimeD  (None, 8, 86, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_155 (TimeD  (None, 8, 86, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_156 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_157 (TimeD  (None, 8, 43, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_158 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_159 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_160 (TimeD  (None, 8, 43, 32)        3104      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_161 (TimeD  (None, 8, 43, 32)        128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_162 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_163 (TimeD  (None, 8, 21, 32)        0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_164 (TimeD  (None, 8, 672)           0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_165 (TimeD  (None, 8, 32)            21536     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_166 (TimeD  (None, 8, 32)            128       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_167 (TimeD  (None, 8, 32)            0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,601\n",
      "Trainable params: 52,929\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "beat_length = 345\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(seq_length, beat_length, num_feats))\n",
    "\n",
    "## Layers 1-6 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(input)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 7-12 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 13-19 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layers 19-24 - time-distributed convolutional block\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool1D(pool_size=2))(x)\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layer 25 - time-distributed flatten\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "## Layer 26 - time-distributed dense\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation='relu'))(x)\n",
    "\n",
    "## Layer 27 - time-distributed batch norm\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\n",
    "\n",
    "## Layer 28 - time-distributed dropout\n",
    "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5))(x)\n",
    "\n",
    "## Layer 29 - LSTM\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_lstm_model_3 = tf.keras.Model(input, output, name=\"cnn_lstm_model_3\")\n",
    "cnn_lstm_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f94b594-e533-435a-933a-05e09c37c734",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_lstm_model_3.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ace8ee3-a6c4-4323-84a0-b8c0aee11def",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "353/353 [==============================] - 98s 258ms/step - loss: 0.5851 - binary_accuracy: 0.5000 - val_loss: 0.5710 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/2\n",
      "353/353 [==============================] - 91s 257ms/step - loss: 0.4927 - binary_accuracy: 0.5000 - val_loss: 0.4787 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb73d0769d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm_model_3.fit(x=model_3_data_train, y=model_3_labels_train, validation_data=[model_3_data_test, model_3_labels_test], batch_size=32, epochs=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6274a58-a243-4f85-a788-ffd7f576e906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 20:25:27.167684: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 512, 32)           128       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512, 32)          128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 512, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 256, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256, 32)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 256, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 256, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 128, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128, 32)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 128, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 128, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 64, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64, 32)            0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 64, 32)            3104      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 64, 32)            3104      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 32, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 32)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                32800     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,635\n",
      "Trainable params: 56,963\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "beat_length = 512\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(beat_length,num_feats))\n",
    "\n",
    "## Layers 1-6 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layers 7-12 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layers 13-19 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layers 19-24 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 25 - flatten\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "## Layer 26 - dense\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "## Layer 27 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 28 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 29 - dense\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "cnn_model = tf.keras.Model(input, output, name=\"cnn_model\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2149bf10-08b6-4a45-be4a-6e294b09c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d47e8c6-32db-49a4-b40c-312fe4aba9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e962767e-fa2b-4b64-8136-385790fcf581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-44974961a0bc5c55\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-44974961a0bc5c55\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4db06c5b-eeb4-46ff-8b67-db20d8dbf90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2442/2442 [==============================] - 257s 104ms/step - loss: 1.1028 - categorical_accuracy: 0.4171 - val_loss: 0.9471 - val_categorical_accuracy: 0.4993\n",
      "Epoch 2/50\n",
      "2442/2442 [==============================] - 259s 106ms/step - loss: 0.9675 - categorical_accuracy: 0.5059 - val_loss: 0.9209 - val_categorical_accuracy: 0.5204\n",
      "Epoch 3/50\n",
      "2442/2442 [==============================] - 254s 104ms/step - loss: 0.9513 - categorical_accuracy: 0.5156 - val_loss: 0.9116 - val_categorical_accuracy: 0.5293\n",
      "Epoch 4/50\n",
      "2442/2442 [==============================] - 256s 105ms/step - loss: 0.9458 - categorical_accuracy: 0.5198 - val_loss: 0.9228 - val_categorical_accuracy: 0.5295\n",
      "Epoch 5/50\n",
      "2442/2442 [==============================] - 256s 105ms/step - loss: 0.9429 - categorical_accuracy: 0.5205 - val_loss: 0.9110 - val_categorical_accuracy: 0.5344\n",
      "Epoch 6/50\n",
      "2442/2442 [==============================] - 260s 107ms/step - loss: 0.9408 - categorical_accuracy: 0.5216 - val_loss: 0.9115 - val_categorical_accuracy: 0.5315\n",
      "Epoch 7/50\n",
      "2442/2442 [==============================] - 259s 106ms/step - loss: 0.9381 - categorical_accuracy: 0.5227 - val_loss: 0.9287 - val_categorical_accuracy: 0.5241\n",
      "Epoch 8/50\n",
      "2442/2442 [==============================] - 289s 118ms/step - loss: 0.9368 - categorical_accuracy: 0.5239 - val_loss: 0.8922 - val_categorical_accuracy: 0.5468\n",
      "Epoch 9/50\n",
      "2442/2442 [==============================] - 281s 115ms/step - loss: 0.9363 - categorical_accuracy: 0.5268 - val_loss: 0.9123 - val_categorical_accuracy: 0.5277\n",
      "Epoch 10/50\n",
      "2442/2442 [==============================] - 266s 109ms/step - loss: 0.9318 - categorical_accuracy: 0.5270 - val_loss: 0.9092 - val_categorical_accuracy: 0.5450\n",
      "Epoch 11/50\n",
      "2442/2442 [==============================] - 428s 175ms/step - loss: 0.9318 - categorical_accuracy: 0.5281 - val_loss: 0.9205 - val_categorical_accuracy: 0.5287\n",
      "Epoch 12/50\n",
      "2442/2442 [==============================] - 384s 157ms/step - loss: 0.9325 - categorical_accuracy: 0.5280 - val_loss: 0.9465 - val_categorical_accuracy: 0.5138\n",
      "Epoch 13/50\n",
      "2442/2442 [==============================] - 263s 108ms/step - loss: 0.9310 - categorical_accuracy: 0.5298 - val_loss: 0.9666 - val_categorical_accuracy: 0.5107\n",
      "Epoch 14/50\n",
      "2442/2442 [==============================] - 262s 107ms/step - loss: 0.9272 - categorical_accuracy: 0.5297 - val_loss: 0.9729 - val_categorical_accuracy: 0.4926\n",
      "Epoch 15/50\n",
      "2442/2442 [==============================] - 265s 108ms/step - loss: 0.9258 - categorical_accuracy: 0.5310 - val_loss: 0.8991 - val_categorical_accuracy: 0.5379\n",
      "Epoch 16/50\n",
      "2442/2442 [==============================] - 263s 108ms/step - loss: 0.9261 - categorical_accuracy: 0.5310 - val_loss: 0.9303 - val_categorical_accuracy: 0.5257\n",
      "Epoch 17/50\n",
      "2442/2442 [==============================] - 263s 108ms/step - loss: 0.9276 - categorical_accuracy: 0.5308 - val_loss: 0.8869 - val_categorical_accuracy: 0.5436\n",
      "Epoch 18/50\n",
      "2442/2442 [==============================] - 270s 110ms/step - loss: 0.9250 - categorical_accuracy: 0.5341 - val_loss: 0.9469 - val_categorical_accuracy: 0.5199\n",
      "Epoch 19/50\n",
      "2442/2442 [==============================] - 258s 106ms/step - loss: 0.9263 - categorical_accuracy: 0.5309 - val_loss: 0.9501 - val_categorical_accuracy: 0.5128\n",
      "Epoch 20/50\n",
      "2442/2442 [==============================] - 258s 106ms/step - loss: 0.9231 - categorical_accuracy: 0.5326 - val_loss: 0.9380 - val_categorical_accuracy: 0.5131\n",
      "Epoch 21/50\n",
      "2442/2442 [==============================] - 249s 102ms/step - loss: 0.9234 - categorical_accuracy: 0.5340 - val_loss: 0.9675 - val_categorical_accuracy: 0.4970\n",
      "Epoch 22/50\n",
      "2442/2442 [==============================] - 258s 106ms/step - loss: 0.9237 - categorical_accuracy: 0.5339 - val_loss: 0.9553 - val_categorical_accuracy: 0.5125\n",
      "Epoch 23/50\n",
      "2442/2442 [==============================] - 253s 104ms/step - loss: 0.9214 - categorical_accuracy: 0.5360 - val_loss: 1.0671 - val_categorical_accuracy: 0.3894\n",
      "Epoch 24/50\n",
      "2442/2442 [==============================] - 256s 105ms/step - loss: 0.9206 - categorical_accuracy: 0.5350 - val_loss: 0.8909 - val_categorical_accuracy: 0.5451\n",
      "Epoch 25/50\n",
      "2442/2442 [==============================] - 258s 106ms/step - loss: 0.9200 - categorical_accuracy: 0.5360 - val_loss: 0.8975 - val_categorical_accuracy: 0.5385\n",
      "Epoch 26/50\n",
      "2442/2442 [==============================] - 259s 106ms/step - loss: 0.9216 - categorical_accuracy: 0.5356 - val_loss: 0.9276 - val_categorical_accuracy: 0.5239\n",
      "Epoch 27/50\n",
      "2442/2442 [==============================] - 254s 104ms/step - loss: 0.9209 - categorical_accuracy: 0.5359 - val_loss: 0.8900 - val_categorical_accuracy: 0.5444\n",
      "Epoch 00027: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa55e1e3450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(x=model_4_data_train, y=model_4_labels_train, validation_data=[model_4_data_test, model_4_labels_test], batch_size=32, epochs=50, verbose=True, callbacks=[callback, tensorboard_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76d7bb-388e-4bc5-9da0-799d03048b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
